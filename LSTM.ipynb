{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "np.random.seed(20)\n",
    "\n",
    "\n",
    "tweets_data = pd.read_csv('dataset_final_vader.csv', delimiter=';')\n",
    "new_tweets_data = pd.read_csv('fix_with_slang.csv', delimiter=';')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2665    1\n",
      "2600    1\n",
      "2356    1\n",
      "Name: label_vader, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets = tweets_data['origin_text_id']\n",
    "labels = tweets_data['label_vader']\n",
    "\n",
    "labels_count = labels.value_counts()\n",
    "labels_count.plot(kind='bar')\n",
    "print(labels_count.value_counts())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['etle', 'etle', 'tp', 'msh', 'manual', 'ngambil', 'fotonya', 'emang', 'tuolol', 'ada', 'cctv', 'napa', 'g', 'di', 'manfaatkan', 'oiya', 'lupa', 'nanti', 'bisa', 'di', 'edit', 'yak']\n"
     ]
    }
   ],
   "source": [
    "split_bucket =[]\n",
    "tkr = RegexpTokenizer('[a-zA-Z@]+')\n",
    "for i, line in enumerate(tweets):\n",
    "    tweet = line.split()\n",
    "    tweet = tkr.tokenize(str(tweet))\n",
    "    split_bucket.append(tweet)\n",
    "\n",
    "print(split_bucket[-1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "['etle',\n 'etle',\n 'tp',\n 'msh',\n 'manual',\n 'ngambil',\n 'foto',\n 'emang',\n 'tuolol',\n 'ada',\n 'cctv',\n 'napa',\n 'g',\n 'di',\n 'manfaat',\n 'oiya',\n 'lupa',\n 'nanti',\n 'bisa',\n 'di',\n 'edit',\n 'yak']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_bucket[-1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/7621 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c31a362b69aa4b36bfe5fb6933ff8224"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "[['kembangkan',\n  'etle',\n  ',',\n  '7',\n  'polda',\n  'dapat',\n  'penghargaan',\n  'di',\n  'rakernis',\n  'fungsi',\n  'gakkum'],\n ['sosialisasi', 'etle', 'dan', 'app', 'smart', 'city'],\n ['berita',\n  'populer',\n  'kumparanoto',\n  ',',\n  'selasa',\n  '1312',\n  'detail',\n  'vespa',\n  'batik',\n  'seharga',\n  'rp',\n  '77',\n  'juta',\n  ',',\n  'cara',\n  'kerja',\n  'dan',\n  'jenis',\n  'pelanggaran',\n  'tilang',\n  'etle',\n  'mobile',\n  '.'],\n ['mimin',\n  'kasih',\n  'info',\n  'ya',\n  'gaes',\n  ',',\n  'kita',\n  'mau',\n  'uji',\n  'coba',\n  'etle',\n  'di',\n  'wilayah',\n  'tangerang',\n  'kota',\n  'nih',\n  '.',\n  'yukss',\n  'patuhi',\n  'peraturan',\n  'lalu',\n  'lintas',\n  ',',\n  'biar',\n  'ngga',\n  'dapet',\n  'surat',\n  'cinta',\n  'dari',\n  'mimin'],\n ['personil',\n  'lalu',\n  'lintas',\n  'polres',\n  'badung',\n  'melaksanakan',\n  'teguran',\n  'secara',\n  'humanis',\n  'kepada',\n  'masyarakat',\n  'yang',\n  'tidak',\n  'mempergunakan',\n  'helm',\n  '.',\n  '.']]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sentences = [word_tokenize(x) for x in tqdm(tweets)]\n",
    "sentences[:5]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import os\n",
    "model =Word2Vec(sentences=sentences, vector_size=128, window=5, min_count=3, workers=4, epochs=1000, sg=0, hs=0 )\n",
    "os.makedirs(\"model/w2v/\", exist_ok=True)\n",
    "model.save(\"model/w2v/etle_dataset_origin_text.model\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "load = Word2Vec.load(\"model/w2v/etle_dataset_origin_text.model\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "w2v = load.wv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "['.',\n ',',\n 'etle',\n 'tilang',\n 'di',\n 'elektronik',\n 'dan',\n 'yang',\n 'kamera',\n 'etilang',\n 'lintas',\n 'polda',\n 'ini',\n 'lalu',\n 'ada',\n 'manual',\n 'mobile',\n 'pelanggaran',\n 'untuk',\n 'polres',\n 'polisi',\n 'sosialisasi',\n 'dengan',\n 'bisa',\n 'kena',\n 'yg',\n 'akan',\n 'lantas',\n '2022',\n 'polri',\n 'pelanggar',\n 'masyarakat',\n 'tidak',\n 'kendaraan',\n 'atau',\n 'kota',\n 'kapolri',\n 'jalan',\n 'pengendara',\n 'metro',\n 'pungli',\n 'ke',\n 'mulai',\n 'traffic',\n 'ya',\n 'law',\n 'itu',\n 'ga',\n 'enforcement',\n 'satlantas',\n 'sistem',\n 'aplikasi',\n 'hari',\n 'sudah',\n 'kepada',\n 'cara',\n 'jaya',\n 'menggunakan',\n 'surat',\n 'penindakan',\n 'electronic',\n 'ditlantas',\n 'giat',\n 'pada',\n 'dari',\n 'secara',\n 'dalam',\n 'juga',\n 'plat',\n 'lagi',\n 'mobil',\n 'zebra',\n 'operasi',\n 'aja',\n 'gak',\n 'online',\n 'tak',\n 'kalo',\n 'melalui',\n 'tapi',\n 'hukum',\n 'cctv',\n 'nomor',\n 'tercapture',\n 'korlantas',\n 'banyak',\n 'sim',\n 'pak',\n 'melaksanakan',\n 'oleh',\n 'melakukan',\n 'smart',\n 'lebih',\n '1',\n 'penerapan',\n 'stnk',\n 'city',\n 'pakai',\n 'masih',\n 'bakal',\n 'banyuasin',\n 'saat',\n 'pake',\n 'tertib',\n 'informasi',\n 'jadi',\n 'data',\n 'helm',\n 'berlaku',\n 'dulur',\n 'kito',\n 'polresta',\n 'apa',\n 'karena',\n 'terkait',\n 'bayar',\n 'belum',\n 'lewat',\n 'baru',\n 'jakarta',\n 'motor',\n 'buat',\n 'saya',\n 'mau',\n 'kalau',\n 'desember',\n 'nya',\n 'bali',\n 'selama',\n 'kebijakan',\n 'berlalu',\n 'melanggar',\n '3',\n 'kan',\n '2',\n 'statis',\n 'terapkan',\n 'udah',\n 'pelat',\n 'tol',\n 'stop',\n 'polantas',\n 'denda',\n 'sat',\n 'sama',\n 'langsung',\n 'wilayah',\n 'bandung',\n 'titik',\n 'baik',\n 'biar',\n 'sih',\n 'diberlakukan',\n 'cek',\n 'terhadap',\n 'no',\n 'pelayanan',\n 'begini',\n 'konfirmasi',\n 'polsek',\n 'hanya',\n '4',\n 'diterapkan',\n 'warga',\n 'harus',\n 'prabumulih',\n 'gar',\n 'aturan',\n 'sekarang',\n 'lampu',\n 'coba',\n 'presisi',\n 'personil',\n 'dapat',\n 'nih',\n 'siap',\n 'kita',\n '5',\n 'agar',\n 'via',\n 'menerapkan',\n 'petugas',\n 'jangan',\n 'salah',\n 'jenis',\n 'riau',\n 'jumlah',\n 'jam',\n 'semua',\n 'telah',\n 'depan',\n 'penegakan',\n 'selatan',\n 'punya',\n 'kepolisian',\n 'listyo',\n 'foto',\n 'terekam',\n 'aku',\n 'oktober',\n 'orang',\n 'saja',\n 'rtmc',\n 'dilakukan',\n 'pemasangan',\n '10',\n 'tahun',\n 'sigit',\n 'app',\n 'mengenai',\n 'dilarang',\n 'berikut',\n 'memaksimalkan',\n 'pol',\n '6',\n 'klo',\n 'bukan',\n 'penggunaan',\n 'terus',\n 'jalur',\n 'sumsel',\n 'para',\n 'jenderal',\n 'sobat',\n 'tentang',\n 'resmi',\n 'pekanbaru',\n 'e',\n 'patroli',\n 'hingga',\n 'tanpa',\n 'hp',\n 'oku',\n 'ditilang',\n 'ditempat',\n 'adanya',\n 'daerah',\n 'berkendara',\n '1x24',\n '11',\n 'pengurusan',\n 'simak',\n 'kegiatan',\n 'dakgar',\n 'berlakukan',\n 'uji',\n 'lalin',\n 'memberikan',\n 'pengaduan',\n 'teguran',\n 'prabowo',\n 'semoga',\n 'tetap',\n 'indonesia',\n 'si',\n 'merah',\n 'lalulintas',\n 'arus',\n 'bersama',\n 'banget',\n 'dgn',\n 'tilangelektronik',\n 'drone',\n 's',\n 'anggota',\n 'to',\n 'makin',\n 'november',\n 'lakukan',\n 'terpasang',\n 'maksimalkan',\n 'super',\n 'raya',\n 'pemberlakuan',\n 'selasa',\n 'skck',\n 'bengkulu',\n 'pos',\n 'tau',\n 'kerja',\n 'seluruh',\n '2023',\n 'balada',\n 'yuk',\n 'perlu',\n 'bukti',\n 'handheld',\n 'pasang',\n 'g20',\n 'kasat',\n 'kapolda',\n 'beberapa',\n 'pas',\n 'ne',\n 'pernah',\n 'info',\n 'dr',\n 'dirlantas',\n 'jika',\n 'bhabinkamtibmas',\n 'cuma',\n 'unit',\n 'hindari',\n 'udh',\n 'menghindari',\n 'agung',\n 'jaga',\n 'banten',\n 'empat',\n 'acara',\n 'malah',\n 'sanksi',\n 'kini',\n 'setelah',\n 'listrik',\n 'jateng',\n '14',\n 'sinergi',\n 'hal',\n 'sejumlah',\n 'gimana',\n 'k',\n 'kondusifitas',\n 'sampai',\n 'pengamanan',\n 'jawa',\n 'arahan',\n 'j',\n 'tersebut',\n 'dulu',\n 'h',\n 'timur',\n 'candi',\n 'penilangan',\n 'tp',\n 'pataka',\n 'menilang',\n 'tengah',\n 'program',\n 'polrestabes',\n 'rawan',\n 'tanggal',\n 'sebagai',\n 'peraturan',\n 'dipasang',\n 'segera',\n 'bagi',\n 'berlalulintas',\n 'sejak',\n 'teknologi',\n '8',\n 'ma',\n 'kabupaten',\n 'gitu',\n 'patuhi',\n 'daftar',\n 'terjaring',\n 'tahu',\n 'terjadi',\n 'kantor',\n 'efektif',\n 'rabu',\n 'soal',\n 'berbasis',\n 'sesuai',\n 'diganti',\n 'jajaran',\n 'takut',\n 'bikin',\n 'ditindak',\n 'emang',\n 'selalu',\n 'tuh',\n 'lokasi',\n 'm',\n 'pemantauan',\n 'aceh',\n 'lawang',\n 'jalanan',\n 'instruksi',\n 'apakah',\n 'gw',\n 'tangerang',\n 'tertangkap',\n 'presidensi',\n 'kami',\n 'demi',\n 'penjagaan',\n 'kombes',\n 'i',\n 'padang',\n 'apresiasi',\n 'sangat',\n 'humanis',\n 'menindak',\n 'negara',\n '00',\n 'dki',\n 'kampanye',\n 'seperti',\n 'pelaksanaan',\n 'keselamatan',\n 'menjadi',\n 'gunakan',\n 'ternyata',\n 'dukung',\n 'oknum',\n 'malam',\n 'selengkapnya',\n 'nanti',\n 'tindak',\n 'kok',\n 'minta',\n 'copot',\n 'kecelakaan',\n 'mana',\n 'pajak',\n 'bagaimana',\n 'ribuan',\n 'a',\n 'memang',\n 'pagi',\n 'penipuan',\n 'mendownload',\n 'sbb',\n 'kanit',\n 'catat',\n 'dia',\n 'mekanisme',\n 'padahal',\n 'palsu',\n 'mengurangi',\n 'jd',\n 'larang',\n 'pemotor',\n 'incar',\n 'rangka',\n 'anda',\n 'dua',\n 'utk',\n 'tambah',\n 'boleh',\n 'edukasi',\n 'sosialisasikan',\n 'sering',\n 'mendapatkan',\n 'waspada',\n 'baca',\n 'kamis',\n 'mudah',\n 'ruas',\n 'rumah',\n 'mereka',\n 'putih',\n 'bagus',\n 'satu',\n 'ii',\n 'razia',\n 'lain',\n 'setuju',\n 'mah',\n 'menindaklanjuti',\n 'ruangan',\n 'kompolnas',\n 'senin',\n 'memberlakukan',\n 'mewujudkan',\n 'pengguna',\n 'maupun',\n 'pasti',\n 'tangsel',\n 'bogor',\n 'nah',\n 'langkah',\n '22',\n 'beserta',\n 'besar',\n 'sebanyak',\n 'tinggal',\n 'ni',\n 'gk',\n 'gini',\n 'surabaya',\n 'lah',\n 'wajah',\n 'mungkin',\n 'bgt',\n 'na',\n 'd',\n 'jg',\n 'menghimbau',\n 'serta',\n 'nopol',\n 'alamat',\n 'tdk',\n 'merupakan',\n 'kab',\n 'mari',\n 'akp',\n 'pengemudi',\n 'sukoharjo',\n 'kasus',\n 'soalnya',\n 'masuk',\n 'tiap',\n 'namun',\n 'ops',\n 'pulau',\n 'beroperasi',\n 'aipda',\n 'kecepatan',\n 'bener',\n 'store',\n 'play',\n 'camera',\n 'manis',\n 'sp2hp',\n 'ayo',\n 'dong',\n 'kenapa',\n 'balik',\n 'wna',\n 'sasaran',\n 'selain',\n 'disiplin',\n 'krn',\n 'awas',\n '7',\n 'gua',\n 'talam',\n 'siapsiap',\n 'launching',\n 'aman',\n 'semakin',\n 'membuat',\n 'terkena',\n 'kasih',\n 'larangan',\n 'video',\n 'kamu',\n 'modus',\n 'dah',\n 'mendukung',\n 'atas',\n 'ganti',\n 'ribu',\n 'setiap',\n 'parkir',\n 'deteksi',\n 'jelas',\n 'minggu',\n 'katanya',\n '13',\n 'ponsel',\n 'che',\n 'diluncurkan',\n 'min',\n 'adalah',\n 'lubuklinggau',\n 'canggih',\n 'berjalan',\n 'blokir',\n 'berita',\n 'radio',\n 'besok',\n 'pemilik',\n 'rambu',\n 'ratusan',\n 'sidang',\n 'lepas',\n 'siapkan',\n 'cirebon',\n 'nama',\n 'dapet',\n 'gue',\n 'kamsel',\n 'lahat',\n 'jabar',\n 'sambut',\n 'waktu',\n 'halo',\n 'sabtu',\n 'dapatkan',\n 'jumat',\n 'ciptakan',\n 'biasa',\n 'sumatera',\n 'diblokir',\n 'paling',\n 'skrg',\n 'hibah',\n 'dikirim',\n 'simpang',\n 'download',\n 'langgar',\n 'lapangan',\n 'kunto',\n 'meski',\n 'dilaksanakan',\n 'direktorat',\n 'memiliki',\n 'hatihati',\n 'sdh',\n 'pertama',\n 'kata',\n 'kak',\n 'kembali',\n 'deh',\n 'selamat',\n 'wkwk',\n 'liat',\n 'nilang',\n 'g',\n 'gelar',\n 'lampung',\n 'kapolres',\n 'meningkat',\n 'merasa',\n 'gakkum',\n 'mengedepankan',\n 'raja',\n 'tinggi',\n 'kepri',\n 'guna',\n 'tilangnya',\n 'ambon',\n 'khusus',\n 'suara',\n 'kedepankan',\n 'peran',\n 'per',\n 'batam',\n 'mengikuti',\n 'kayak',\n 'jl',\n 'recognition',\n 'dihapus',\n 'penjelasan',\n 'humas',\n 'samsat',\n 'harusnya',\n 'berarti',\n 'yaa',\n 'face',\n 'bawa',\n 'sepeda',\n 'batas',\n 'trus',\n 'mendeteksi',\n 'probolinggo',\n 'lainnya',\n 'fitur',\n '1312',\n 'tempat',\n 'sampe',\n 'pun',\n 'tiga',\n 'liar',\n 'proses',\n 'himbauan',\n 'perintah',\n 'sini',\n 'terobosan',\n 'mencegah',\n 'mencatat',\n 'bulan',\n 'sendiri',\n 'ditiadakan',\n 'dg',\n 'perangkat',\n 'blm',\n 'meluncurkan',\n 'muara',\n 'terima',\n 'kejaksaan',\n 'jatim',\n 'laka',\n 'bilang',\n 'tetep',\n 'bs',\n 'pihak',\n 'nakal',\n 'difoto',\n 'suka',\n 'lg',\n 'km',\n 'b',\n 'tercatat',\n 'elektronic',\n 'eh',\n 'tegas',\n 'trans',\n 'pembayaran',\n 'warna',\n 'siang',\n '70',\n 'dilengkapi',\n 'irjen',\n 'dimana',\n 'lama',\n 'arah',\n 'bjp',\n 'ngga',\n 'pesan',\n 'portable',\n 'didampingi',\n 'kl',\n 'bingung',\n 'enim',\n 'pengadaan',\n 'paham',\n 'karna',\n 'sadar',\n 'bahwa',\n 'nu',\n 'publik',\n 'januari',\n 'gorontalo',\n 'dlm',\n 'viral',\n 'lihat',\n 'diminta',\n 'dekat',\n 'wajib',\n 'ilir',\n 'berikan',\n 'nai',\n 'subang',\n 'alat',\n 'dll',\n 'tepat',\n 'kalian',\n 'asisten',\n 'nggak',\n 'sekaligus',\n 'sedang',\n 'ogan',\n 'bermotor',\n 'cinta',\n '16',\n 'kurang',\n 'nomer',\n 'keliling',\n 'lupa',\n 'sumbar',\n 'hapus',\n 'camat',\n 'dendanya',\n 'tindakan',\n 'ketika',\n 'komisioner',\n 'wong',\n 'merekam',\n 'berupa',\n 'cukup',\n 'taat',\n 'n',\n 'sabuk',\n 'rekam',\n 'komering',\n 'wkwkwk',\n 'melarang',\n 'gedung',\n 'kaya',\n 'dinas',\n 'tanya',\n 'blitar',\n 'korban',\n 'pekan',\n 'ganjil',\n 'genap',\n 'memantau',\n 'begitu',\n 'penjelasannya',\n 'semenjak',\n 'badung',\n 'lawan',\n 'dit',\n 'awal',\n 'apalagi',\n 'memasang',\n 'banyumas',\n 'patuh',\n '108',\n 'ruang',\n 'antara',\n 'sebelum',\n 'duit',\n 'makassar',\n 'kasubdit',\n 'peniadaan',\n 'protokol',\n 'dishub',\n 'musi',\n 'kecamatan',\n 'pelanggarannya',\n '24',\n '250',\n 'pantau',\n 'barat',\n '15',\n 'akhirnya',\n 'sebelumnya',\n 'rasa',\n 'yakin',\n 'kali',\n 'kari',\n 'negeri',\n 'dikmas',\n 'sekali',\n 'dijalan',\n 'supaya',\n 'luncurkan',\n 'berani',\n 'kira',\n 'sambil',\n 'platnya',\n 'lppl',\n 'korupsi',\n 'ingat',\n 'rakyat',\n '9',\n 'pengembangan',\n 'polisinya',\n 'cepat',\n 'dikasih',\n 'pn',\n 'kirim',\n 'whatsapp',\n 'suatu',\n 'nantinya',\n 'kembangkan',\n 'iptu',\n 'caranya',\n 'fm',\n 'benar',\n 'live',\n 'cc',\n 'prof',\n 'penting',\n 'dpt',\n 'tarik',\n 'serang',\n 'mengatakan',\n 'gmn',\n 'kesadaran',\n 'yo',\n 'loh',\n 'kepala',\n 'materi',\n 'dimaksimalkan',\n 'iya',\n 'tadi',\n 'mampu',\n 'doang',\n 'nataru',\n 'tahap',\n 'status',\n 'layanan',\n 'muhammad',\n 'berdasarkan',\n 'pengecekan',\n 'besaran',\n 'media',\n 'uang',\n 'tolong',\n 'damai',\n 'menghilangkan',\n 'dana',\n 'ds',\n 'ingatkan',\n 'mantap',\n 'rri',\n 'posko',\n 'cari',\n 'pd',\n 'pan',\n 'stiker',\n 'batu',\n 'mengetahui',\n 'tangan',\n 'website',\n 'perkara',\n 'optimalkan',\n 'kapan',\n 'meningkatkan',\n 'komisi',\n 'mati',\n 'bapak',\n 'jauh',\n 'pengawasan',\n 'cm',\n 'nasional',\n 'mata',\n 'apel',\n 'taslim',\n 'ketilang',\n 'uu',\n 'mempergunakan',\n 'penghargaan',\n 'knalpot',\n 'sudirman',\n 'belakang',\n 'keren',\n 'tilangetle',\n 'mas',\n 'desa',\n 'maka',\n 'direkam',\n 'sulteng',\n 'pemanfaatan',\n 'menuju',\n 'sengaja',\n 'kendaraannya',\n 'tetapi',\n 'gampang',\n 'beda',\n 'ngurus',\n 'keluar',\n 'adapun',\n '20',\n 'utama',\n 'maksimal',\n 'meniadakan',\n 'preventive',\n 'siapa',\n 'bang',\n 'gt',\n 'sebut',\n 'ibu',\n 'imigrasi',\n 'lilin',\n 'sepanjang',\n 'melebihi',\n '12',\n 'muncul',\n 'masalah',\n 'nunggu',\n 'trafic',\n '100',\n 'mohon',\n 'pengenal',\n 'org',\n 'hati',\n 'efek',\n 'subdit',\n 'biasanya',\n 'web',\n 'lokasinya',\n 'asing',\n 'dinilai',\n 'bila',\n 'hai',\n 'school',\n 'police',\n 'tu',\n 'kerjanya',\n '30',\n 'yaitu',\n 'hoy',\n 'angka',\n 'muaradua',\n 'terpadu',\n 'bagian',\n 'korps',\n 'sehingga',\n 'beli',\n 'kawasan',\n 'msh',\n 'bahkan',\n 'ambil',\n 'menurut',\n 'misal',\n 'gantinya',\n 'jelang',\n 'fungsi',\n 'lakban',\n 'lancar',\n 'guru',\n 'chairuddin',\n 'ingin',\n 'hitam',\n 'aksi',\n 'kelemahan',\n 'mobilnya',\n 'cegah',\n 'ikut',\n '2009',\n 'chhe',\n 'mending',\n 'jaman',\n 'jombang',\n 'enforvement',\n 'palu',\n 'tepatnya',\n 'brigjen',\n 'topik',\n 'termasuk',\n 'kalsel',\n 'usah',\n ...]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.index_to_key"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.51987576, -0.11301365,  0.86377126, ..., -0.4791857 ,\n         0.5146075 , -1.1546612 ],\n       [-0.6688522 , -0.55416536,  1.2798222 , ..., -0.453539  ,\n         0.26390088, -1.440308  ],\n       [ 0.1358714 , -3.6266193 ,  0.07829557, ...,  1.7402557 ,\n        -0.77879614,  0.9131657 ],\n       ...,\n       [-2.6406634 , -0.05117225, -0.92996335, ..., -2.2555313 ,\n        -0.8254951 ,  1.7208917 ],\n       [ 0.3294125 , -4.8576927 ,  1.1033006 , ..., -1.40378   ,\n        -1.4137754 ,  1.9022019 ],\n       [-0.81305736,  0.9110352 ,  0.37552348, ...,  0.46394384,\n         1.0125691 , -1.2304474 ]], dtype=float32)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.vectors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "128"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.vector_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 2.1157606 , -0.12685345,  1.5248972 , -0.95952207, -2.286263  ,\n       -1.5288812 , -0.21539417,  2.4283743 , -2.482218  ,  3.918049  ,\n        3.9015622 , -0.54111063,  0.09709703,  1.4287821 ,  2.524994  ,\n        0.5084887 ,  1.2018636 ,  0.31482697, -3.8784752 , -0.2934743 ,\n        0.42448187, -0.41837513,  0.49797714, -1.5234358 , -0.629219  ,\n       -0.01684473,  4.2627497 ,  1.0899798 , -0.03885339, -4.591828  ,\n        0.83279026, -0.706956  ,  4.5625935 , -4.8738937 ,  0.9138127 ,\n       -1.8241602 ,  1.6703519 ,  0.36238486, -5.431518  , -2.3831906 ,\n       -4.517662  ,  3.0880103 ,  2.045776  , -4.2764244 , -2.733722  ,\n       -0.39301768,  4.0736184 , -0.67163205, -3.4500792 ,  0.13262872,\n       -0.30564135, -2.140066  ,  2.96824   , -0.26480174, -0.13205644,\n       -1.2466093 , -0.85349894,  0.6327887 , -0.6710296 ,  1.0454823 ,\n       -2.7736437 ,  3.2192435 ,  1.0030837 ,  3.0382364 , -0.931653  ,\n        0.8921258 , -0.02530616,  0.27140406, -1.5704445 ,  0.8619415 ,\n       -0.13250162, -0.43909574, -6.3972397 , -1.5780897 ,  2.5450425 ,\n       -1.3898318 , -0.9427667 , -2.6807065 ,  2.6407769 , -3.281437  ,\n        1.1657735 ,  0.41617584, -3.2713556 , -0.6892625 ,  2.3233178 ,\n       -1.0788938 , -0.79078084, -2.5235214 , -4.530525  ,  3.6151361 ,\n       -0.02269859,  5.1495695 , -0.53024274,  2.9429865 , -1.2999201 ,\n       -2.3518224 , -3.0157726 , -0.09500434, -0.29520705,  1.4120194 ,\n       -2.426555  ,  0.18359649,  4.5801773 , -2.8247023 , -1.3429551 ,\n       -0.90674   ,  4.108201  , -4.220999  ,  3.4429371 , -3.3468988 ,\n       -1.6336784 ,  0.6406046 , -0.36456102,  0.89967656, -1.4636143 ,\n       -2.2429845 , -3.0629253 ,  0.5694036 , -3.2404895 ,  0.82021034,\n       -0.97709477, -3.7344272 ,  0.5355977 ,  1.6040545 ,  0.42469677,\n        4.1240077 , -1.7014047 , -0.03788436], dtype=float32)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.get_vector(\"ojol\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## sanity check"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "[('smkn', 0.41539373993873596),\n ('p', 0.33039793372154236),\n ('dikorupsi', 0.3286185562610626),\n ('just', 0.32326245307922363),\n ('pahami', 0.3108600974082947)]"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.similar_by_word(\"jokowi\", topn=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "initialization of _internal failed without raising an exception",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mSystemError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[43], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mumap\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m UMAP\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mplotly\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexpress\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpx\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\skripsi_bert_ngab\\venv\\lib\\site-packages\\umap\\__init__.py:2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m warn, catch_warnings, simplefilter\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mumap_\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m UMAP\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m catch_warnings():\n",
      "File \u001B[1;32m~\\PycharmProjects\\skripsi_bert_ngab\\venv\\lib\\site-packages\\umap\\umap_.py:28\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msparse\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tril \u001B[38;5;28;01mas\u001B[39;00m sparse_tril, triu \u001B[38;5;28;01mas\u001B[39;00m sparse_triu\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msparse\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcsgraph\u001B[39;00m\n\u001B[1;32m---> 28\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumba\u001B[39;00m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mumap\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistances\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mdist\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mumap\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msparse\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msparse\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\skripsi_bert_ngab\\venv\\lib\\site-packages\\numba\\__init__.py:42\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumba\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdecorators\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (cfunc, generated_jit, jit, njit, stencil,\n\u001B[0;32m     39\u001B[0m                                    jit_module)\n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m# Re-export vectorize decorators and the thread layer querying function\u001B[39;00m\n\u001B[1;32m---> 42\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumba\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mufunc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (vectorize, guvectorize, threading_layer,\n\u001B[0;32m     43\u001B[0m                             get_num_threads, set_num_threads,\n\u001B[0;32m     44\u001B[0m                             set_parallel_chunksize, get_parallel_chunksize,\n\u001B[0;32m     45\u001B[0m                             get_thread_id)\n\u001B[0;32m     47\u001B[0m \u001B[38;5;66;03m# Re-export Numpy helpers\u001B[39;00m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumba\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnumpy_support\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m carray, farray, from_dtype\n",
      "File \u001B[1;32m~\\PycharmProjects\\skripsi_bert_ngab\\venv\\lib\\site-packages\\numba\\np\\ufunc\\__init__.py:3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# -*- coding: utf-8 -*-\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumba\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mufunc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdecorators\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Vectorize, GUVectorize, vectorize, guvectorize\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumba\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mufunc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_internal\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PyUFunc_None, PyUFunc_Zero, PyUFunc_One\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumba\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mufunc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _internal, array_exprs\n",
      "File \u001B[1;32m~\\PycharmProjects\\skripsi_bert_ngab\\venv\\lib\\site-packages\\numba\\np\\ufunc\\decorators.py:3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01minspect\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumba\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mufunc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _internal\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumba\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mufunc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mparallel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ParallelUFuncBuilder, ParallelGUFuncBuilder\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumba\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mregistry\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DelayedRegistry\n",
      "\u001B[1;31mSystemError\u001B[0m: initialization of _internal failed without raising an exception"
     ]
    }
   ],
   "source": [
    "from umap import UMAP\n",
    "import plotly.express as px"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LSTM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7621, 60)\n",
      "Epoch 1/500\n",
      "191/191 [==============================] - 17s 77ms/step - loss: -1.9415 - accuracy: 0.4096 - val_loss: -4.7704 - val_accuracy: 0.4459\n",
      "Epoch 2/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -5.0363 - accuracy: 0.4409 - val_loss: -7.8401 - val_accuracy: 0.4289\n",
      "Epoch 3/500\n",
      "191/191 [==============================] - 16s 86ms/step - loss: -11.0412 - accuracy: 0.4513 - val_loss: -12.9239 - val_accuracy: 0.4538\n",
      "Epoch 4/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -17.4164 - accuracy: 0.4854 - val_loss: -17.2853 - val_accuracy: 0.4616\n",
      "Epoch 5/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -24.0224 - accuracy: 0.4962 - val_loss: -22.3093 - val_accuracy: 0.4656\n",
      "Epoch 6/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -30.4651 - accuracy: 0.5182 - val_loss: -27.3043 - val_accuracy: 0.4689\n",
      "Epoch 7/500\n",
      "191/191 [==============================] - 14s 74ms/step - loss: -38.6786 - accuracy: 0.5207 - val_loss: -32.1785 - val_accuracy: 0.4721\n",
      "Epoch 8/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -45.4243 - accuracy: 0.5325 - val_loss: -36.5907 - val_accuracy: 0.4754\n",
      "Epoch 9/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -51.2881 - accuracy: 0.5243 - val_loss: -39.7017 - val_accuracy: 0.4748\n",
      "Epoch 10/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -59.5199 - accuracy: 0.5328 - val_loss: -46.8843 - val_accuracy: 0.4761\n",
      "Epoch 11/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -64.0026 - accuracy: 0.5289 - val_loss: -49.9114 - val_accuracy: 0.4728\n",
      "Epoch 12/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -72.1190 - accuracy: 0.5369 - val_loss: -56.7681 - val_accuracy: 0.4833\n",
      "Epoch 13/500\n",
      "191/191 [==============================] - 14s 76ms/step - loss: -81.2439 - accuracy: 0.5509 - val_loss: -62.9398 - val_accuracy: 0.4813\n",
      "Epoch 14/500\n",
      "191/191 [==============================] - 14s 75ms/step - loss: -88.6342 - accuracy: 0.5502 - val_loss: -67.1482 - val_accuracy: 0.4885\n",
      "Epoch 15/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -96.0346 - accuracy: 0.5640 - val_loss: -70.2110 - val_accuracy: 0.4833\n",
      "Epoch 16/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -102.8973 - accuracy: 0.5527 - val_loss: -76.3722 - val_accuracy: 0.4807\n",
      "Epoch 17/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -103.6529 - accuracy: 0.5651 - val_loss: -79.1417 - val_accuracy: 0.4774\n",
      "Epoch 18/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -113.9293 - accuracy: 0.5541 - val_loss: -83.9433 - val_accuracy: 0.4911\n",
      "Epoch 19/500\n",
      "191/191 [==============================] - 14s 76ms/step - loss: -121.6637 - accuracy: 0.5641 - val_loss: -88.5796 - val_accuracy: 0.4846\n",
      "Epoch 20/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -129.1283 - accuracy: 0.5627 - val_loss: -94.6745 - val_accuracy: 0.4767\n",
      "Epoch 21/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -136.4193 - accuracy: 0.5730 - val_loss: -99.9124 - val_accuracy: 0.4833\n",
      "Epoch 22/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -141.8895 - accuracy: 0.5686 - val_loss: -103.6199 - val_accuracy: 0.4852\n",
      "Epoch 23/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -149.6384 - accuracy: 0.5753 - val_loss: -107.6426 - val_accuracy: 0.4793\n",
      "Epoch 24/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -159.2719 - accuracy: 0.5760 - val_loss: -111.7745 - val_accuracy: 0.4826\n",
      "Epoch 25/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -167.5612 - accuracy: 0.5805 - val_loss: -117.0421 - val_accuracy: 0.4833\n",
      "Epoch 26/500\n",
      "191/191 [==============================] - 14s 76ms/step - loss: -175.1105 - accuracy: 0.5874 - val_loss: -120.5656 - val_accuracy: 0.4957\n",
      "Epoch 27/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -181.3631 - accuracy: 0.5907 - val_loss: -124.8483 - val_accuracy: 0.4925\n",
      "Epoch 28/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -189.2166 - accuracy: 0.5873 - val_loss: -131.3405 - val_accuracy: 0.4885\n",
      "Epoch 29/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -197.1557 - accuracy: 0.5896 - val_loss: -136.4860 - val_accuracy: 0.5003\n",
      "Epoch 30/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -205.5443 - accuracy: 0.5920 - val_loss: -136.7355 - val_accuracy: 0.4892\n",
      "Epoch 31/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -211.4026 - accuracy: 0.5927 - val_loss: -144.8350 - val_accuracy: 0.4807\n",
      "Epoch 32/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -217.3312 - accuracy: 0.5912 - val_loss: -146.3763 - val_accuracy: 0.4918\n",
      "Epoch 33/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -227.0709 - accuracy: 0.5943 - val_loss: -151.3619 - val_accuracy: 0.4872\n",
      "Epoch 34/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -234.1883 - accuracy: 0.5999 - val_loss: -158.3715 - val_accuracy: 0.4911\n",
      "Epoch 35/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -242.6826 - accuracy: 0.5974 - val_loss: -165.0288 - val_accuracy: 0.4911\n",
      "Epoch 36/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -247.8042 - accuracy: 0.6002 - val_loss: -169.1596 - val_accuracy: 0.4879\n",
      "Epoch 37/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -256.0839 - accuracy: 0.6071 - val_loss: -174.4135 - val_accuracy: 0.4905\n",
      "Epoch 38/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -262.8652 - accuracy: 0.5983 - val_loss: -178.7213 - val_accuracy: 0.4911\n",
      "Epoch 39/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -271.6659 - accuracy: 0.6068 - val_loss: -180.8148 - val_accuracy: 0.4931\n",
      "Epoch 40/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -279.2669 - accuracy: 0.6074 - val_loss: -189.0572 - val_accuracy: 0.4957\n",
      "Epoch 41/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -287.7127 - accuracy: 0.6148 - val_loss: -192.2097 - val_accuracy: 0.4852\n",
      "Epoch 42/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -293.2070 - accuracy: 0.6099 - val_loss: -198.0586 - val_accuracy: 0.4990\n",
      "Epoch 43/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -299.3187 - accuracy: 0.6089 - val_loss: -200.2067 - val_accuracy: 0.5016\n",
      "Epoch 44/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -307.4915 - accuracy: 0.6074 - val_loss: -207.1112 - val_accuracy: 0.4892\n",
      "Epoch 45/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -315.5268 - accuracy: 0.6127 - val_loss: -209.8809 - val_accuracy: 0.4866\n",
      "Epoch 46/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -320.6824 - accuracy: 0.6094 - val_loss: -212.1051 - val_accuracy: 0.4872\n",
      "Epoch 47/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -329.5188 - accuracy: 0.6119 - val_loss: -218.0080 - val_accuracy: 0.4885\n",
      "Epoch 48/500\n",
      "191/191 [==============================] - 16s 81ms/step - loss: -335.7816 - accuracy: 0.6117 - val_loss: -221.6845 - val_accuracy: 0.4970\n",
      "Epoch 49/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -344.3228 - accuracy: 0.6204 - val_loss: -230.6916 - val_accuracy: 0.5043\n",
      "Epoch 50/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -353.1584 - accuracy: 0.6170 - val_loss: -233.1219 - val_accuracy: 0.5016\n",
      "Epoch 51/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -360.1334 - accuracy: 0.6175 - val_loss: -239.9846 - val_accuracy: 0.5036\n",
      "Epoch 52/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -368.6123 - accuracy: 0.6225 - val_loss: -236.8510 - val_accuracy: 0.4984\n",
      "Epoch 53/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -373.5164 - accuracy: 0.6143 - val_loss: -242.5108 - val_accuracy: 0.4997\n",
      "Epoch 54/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -382.4377 - accuracy: 0.6219 - val_loss: -245.9365 - val_accuracy: 0.4970\n",
      "Epoch 55/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -389.7021 - accuracy: 0.6271 - val_loss: -252.8529 - val_accuracy: 0.5030\n",
      "Epoch 56/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -396.7339 - accuracy: 0.6220 - val_loss: -258.0240 - val_accuracy: 0.5023\n",
      "Epoch 57/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -404.1586 - accuracy: 0.6268 - val_loss: -266.1926 - val_accuracy: 0.4964\n",
      "Epoch 58/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -410.7137 - accuracy: 0.6281 - val_loss: -270.8452 - val_accuracy: 0.5062\n",
      "Epoch 59/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -371.1233 - accuracy: 0.5984 - val_loss: -258.9315 - val_accuracy: 0.4918\n",
      "Epoch 60/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -409.6435 - accuracy: 0.5999 - val_loss: -270.4887 - val_accuracy: 0.4977\n",
      "Epoch 61/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -424.6434 - accuracy: 0.6060 - val_loss: -278.9527 - val_accuracy: 0.5075\n",
      "Epoch 62/500\n",
      "191/191 [==============================] - 15s 81ms/step - loss: -433.1195 - accuracy: 0.6201 - val_loss: -286.5205 - val_accuracy: 0.5082\n",
      "Epoch 63/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -442.8091 - accuracy: 0.6165 - val_loss: -286.9819 - val_accuracy: 0.5108\n",
      "Epoch 64/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -450.0297 - accuracy: 0.6248 - val_loss: -295.3422 - val_accuracy: 0.5082\n",
      "Epoch 65/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -459.2747 - accuracy: 0.6237 - val_loss: -291.6355 - val_accuracy: 0.5089\n",
      "Epoch 66/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -465.4641 - accuracy: 0.6252 - val_loss: -303.7682 - val_accuracy: 0.5108\n",
      "Epoch 67/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -473.4881 - accuracy: 0.6230 - val_loss: -305.6811 - val_accuracy: 0.4990\n",
      "Epoch 68/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -475.9948 - accuracy: 0.6247 - val_loss: -306.0197 - val_accuracy: 0.5049\n",
      "Epoch 69/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -485.9582 - accuracy: 0.6227 - val_loss: -309.4556 - val_accuracy: 0.5082\n",
      "Epoch 70/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -494.8107 - accuracy: 0.6242 - val_loss: -316.0002 - val_accuracy: 0.5121\n",
      "Epoch 71/500\n",
      "191/191 [==============================] - 15s 81ms/step - loss: -502.1660 - accuracy: 0.6266 - val_loss: -318.9456 - val_accuracy: 0.5062\n",
      "Epoch 72/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -509.9695 - accuracy: 0.6242 - val_loss: -327.4670 - val_accuracy: 0.5062\n",
      "Epoch 73/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -516.7856 - accuracy: 0.6289 - val_loss: -333.1771 - val_accuracy: 0.5056\n",
      "Epoch 74/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -525.3763 - accuracy: 0.6245 - val_loss: -333.3512 - val_accuracy: 0.5075\n",
      "Epoch 75/500\n",
      "191/191 [==============================] - 15s 81ms/step - loss: -533.5424 - accuracy: 0.6278 - val_loss: -339.8249 - val_accuracy: 0.5069\n",
      "Epoch 76/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -539.1307 - accuracy: 0.6240 - val_loss: -349.9811 - val_accuracy: 0.5062\n",
      "Epoch 77/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -546.2551 - accuracy: 0.6247 - val_loss: -353.4170 - val_accuracy: 0.5043\n",
      "Epoch 78/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -554.6646 - accuracy: 0.6304 - val_loss: -358.6670 - val_accuracy: 0.5102\n",
      "Epoch 79/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -562.3484 - accuracy: 0.6247 - val_loss: -363.5481 - val_accuracy: 0.5056\n",
      "Epoch 80/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -569.4946 - accuracy: 0.6329 - val_loss: -367.5650 - val_accuracy: 0.4984\n",
      "Epoch 81/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -577.6670 - accuracy: 0.6329 - val_loss: -371.7258 - val_accuracy: 0.5049\n",
      "Epoch 82/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -585.3517 - accuracy: 0.6357 - val_loss: -377.1911 - val_accuracy: 0.5023\n",
      "Epoch 83/500\n",
      "191/191 [==============================] - 14s 76ms/step - loss: -590.2803 - accuracy: 0.6348 - val_loss: -382.0886 - val_accuracy: 0.5062\n",
      "Epoch 84/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -596.7943 - accuracy: 0.6322 - val_loss: -376.7671 - val_accuracy: 0.5134\n",
      "Epoch 85/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -605.6815 - accuracy: 0.6339 - val_loss: -387.7460 - val_accuracy: 0.5134\n",
      "Epoch 86/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -611.3990 - accuracy: 0.6345 - val_loss: -390.4025 - val_accuracy: 0.5167\n",
      "Epoch 87/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -620.8068 - accuracy: 0.6363 - val_loss: -396.6345 - val_accuracy: 0.5062\n",
      "Epoch 88/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -630.5085 - accuracy: 0.6391 - val_loss: -399.3275 - val_accuracy: 0.5108\n",
      "Epoch 89/500\n",
      "191/191 [==============================] - 14s 76ms/step - loss: -634.6140 - accuracy: 0.6388 - val_loss: -401.0090 - val_accuracy: 0.5161\n",
      "Epoch 90/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -645.2147 - accuracy: 0.6358 - val_loss: -400.8113 - val_accuracy: 0.5154\n",
      "Epoch 91/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -652.9016 - accuracy: 0.6403 - val_loss: -414.3457 - val_accuracy: 0.5049\n",
      "Epoch 92/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -658.5136 - accuracy: 0.6360 - val_loss: -413.9835 - val_accuracy: 0.5102\n",
      "Epoch 93/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -665.4149 - accuracy: 0.6376 - val_loss: -415.8686 - val_accuracy: 0.5075\n",
      "Epoch 94/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -671.3916 - accuracy: 0.6348 - val_loss: -436.2882 - val_accuracy: 0.5062\n",
      "Epoch 95/500\n",
      "191/191 [==============================] - 14s 76ms/step - loss: -679.8516 - accuracy: 0.6406 - val_loss: -438.5992 - val_accuracy: 0.5121\n",
      "Epoch 96/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -688.2557 - accuracy: 0.6375 - val_loss: -436.9781 - val_accuracy: 0.5043\n",
      "Epoch 97/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -694.8781 - accuracy: 0.6363 - val_loss: -449.0022 - val_accuracy: 0.5069\n",
      "Epoch 98/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -703.7838 - accuracy: 0.6416 - val_loss: -450.3718 - val_accuracy: 0.5082\n",
      "Epoch 99/500\n",
      "191/191 [==============================] - 14s 76ms/step - loss: -712.8666 - accuracy: 0.6426 - val_loss: -451.5587 - val_accuracy: 0.5049\n",
      "Epoch 100/500\n",
      "191/191 [==============================] - 14s 76ms/step - loss: -716.3259 - accuracy: 0.6414 - val_loss: -454.3432 - val_accuracy: 0.5030\n",
      "Epoch 101/500\n",
      "191/191 [==============================] - 14s 76ms/step - loss: -727.0958 - accuracy: 0.6409 - val_loss: -464.9507 - val_accuracy: 0.5069\n",
      "Epoch 102/500\n",
      "191/191 [==============================] - 14s 74ms/step - loss: -734.5576 - accuracy: 0.6453 - val_loss: -466.8140 - val_accuracy: 0.5003\n",
      "Epoch 103/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -739.6632 - accuracy: 0.6411 - val_loss: -467.5966 - val_accuracy: 0.5030\n",
      "Epoch 104/500\n",
      "191/191 [==============================] - 14s 76ms/step - loss: -747.2704 - accuracy: 0.6465 - val_loss: -477.8317 - val_accuracy: 0.5102\n",
      "Epoch 105/500\n",
      "191/191 [==============================] - 14s 76ms/step - loss: -753.2269 - accuracy: 0.6440 - val_loss: -476.6384 - val_accuracy: 0.5089\n",
      "Epoch 106/500\n",
      "191/191 [==============================] - 16s 85ms/step - loss: -760.7355 - accuracy: 0.6401 - val_loss: -475.9027 - val_accuracy: 0.5108\n",
      "Epoch 107/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -768.9361 - accuracy: 0.6450 - val_loss: -481.2062 - val_accuracy: 0.5095\n",
      "Epoch 108/500\n",
      "191/191 [==============================] - 14s 76ms/step - loss: -775.3149 - accuracy: 0.6463 - val_loss: -495.8655 - val_accuracy: 0.5108\n",
      "Epoch 109/500\n",
      "191/191 [==============================] - 14s 75ms/step - loss: -784.0837 - accuracy: 0.6453 - val_loss: -496.5373 - val_accuracy: 0.5095\n",
      "Epoch 110/500\n",
      "191/191 [==============================] - 17s 90ms/step - loss: -788.2355 - accuracy: 0.6424 - val_loss: -500.3717 - val_accuracy: 0.5134\n",
      "Epoch 111/500\n",
      "191/191 [==============================] - 16s 83ms/step - loss: -797.8223 - accuracy: 0.6458 - val_loss: -499.9881 - val_accuracy: 0.5082\n",
      "Epoch 112/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -807.2713 - accuracy: 0.6458 - val_loss: -504.8790 - val_accuracy: 0.5108\n",
      "Epoch 113/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -811.5316 - accuracy: 0.6432 - val_loss: -508.7379 - val_accuracy: 0.5089\n",
      "Epoch 114/500\n",
      "191/191 [==============================] - 16s 83ms/step - loss: -818.4344 - accuracy: 0.6460 - val_loss: -512.9083 - val_accuracy: 0.5095\n",
      "Epoch 115/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -826.7925 - accuracy: 0.6442 - val_loss: -525.2200 - val_accuracy: 0.5115\n",
      "Epoch 116/500\n",
      "191/191 [==============================] - 14s 75ms/step - loss: -836.9149 - accuracy: 0.6488 - val_loss: -524.3757 - val_accuracy: 0.5095\n",
      "Epoch 117/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -844.0721 - accuracy: 0.6498 - val_loss: -534.6043 - val_accuracy: 0.5102\n",
      "Epoch 118/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -851.1333 - accuracy: 0.6429 - val_loss: -530.2473 - val_accuracy: 0.5121\n",
      "Epoch 119/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -858.9702 - accuracy: 0.6467 - val_loss: -541.6528 - val_accuracy: 0.5108\n",
      "Epoch 120/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -864.7623 - accuracy: 0.6465 - val_loss: -556.3946 - val_accuracy: 0.5154\n",
      "Epoch 121/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -871.6229 - accuracy: 0.6488 - val_loss: -560.3113 - val_accuracy: 0.5134\n",
      "Epoch 122/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -879.7742 - accuracy: 0.6504 - val_loss: -559.3719 - val_accuracy: 0.5200\n",
      "Epoch 123/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -887.1890 - accuracy: 0.6478 - val_loss: -550.0717 - val_accuracy: 0.5141\n",
      "Epoch 124/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -892.9907 - accuracy: 0.6455 - val_loss: -575.3207 - val_accuracy: 0.5141\n",
      "Epoch 125/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -900.6374 - accuracy: 0.6462 - val_loss: -572.3725 - val_accuracy: 0.5141\n",
      "Epoch 126/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -907.6503 - accuracy: 0.6476 - val_loss: -580.1702 - val_accuracy: 0.5082\n",
      "Epoch 127/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -915.8349 - accuracy: 0.6435 - val_loss: -579.4345 - val_accuracy: 0.5062\n",
      "Epoch 128/500\n",
      "191/191 [==============================] - 14s 75ms/step - loss: -923.1827 - accuracy: 0.6480 - val_loss: -585.8298 - val_accuracy: 0.5102\n",
      "Epoch 129/500\n",
      "191/191 [==============================] - 14s 75ms/step - loss: -931.0217 - accuracy: 0.6522 - val_loss: -593.7220 - val_accuracy: 0.5148\n",
      "Epoch 130/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -937.8469 - accuracy: 0.6476 - val_loss: -600.1417 - val_accuracy: 0.5128\n",
      "Epoch 131/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -947.2355 - accuracy: 0.6506 - val_loss: -580.1495 - val_accuracy: 0.5180\n",
      "Epoch 132/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -951.6067 - accuracy: 0.6512 - val_loss: -603.2913 - val_accuracy: 0.5141\n",
      "Epoch 133/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -960.7089 - accuracy: 0.6501 - val_loss: -586.9960 - val_accuracy: 0.5167\n",
      "Epoch 134/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -964.0132 - accuracy: 0.6447 - val_loss: -599.8207 - val_accuracy: 0.5167\n",
      "Epoch 135/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -970.9100 - accuracy: 0.6476 - val_loss: -611.0944 - val_accuracy: 0.5134\n",
      "Epoch 136/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -982.4034 - accuracy: 0.6473 - val_loss: -619.5911 - val_accuracy: 0.5154\n",
      "Epoch 137/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -989.0126 - accuracy: 0.6458 - val_loss: -627.3917 - val_accuracy: 0.5095\n",
      "Epoch 138/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -996.2319 - accuracy: 0.6521 - val_loss: -637.5178 - val_accuracy: 0.5115\n",
      "Epoch 139/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1002.5386 - accuracy: 0.6531 - val_loss: -638.9639 - val_accuracy: 0.5082\n",
      "Epoch 140/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -1008.3466 - accuracy: 0.6467 - val_loss: -645.6548 - val_accuracy: 0.5128\n",
      "Epoch 141/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -1020.0733 - accuracy: 0.6481 - val_loss: -647.8322 - val_accuracy: 0.5167\n",
      "Epoch 142/500\n",
      "191/191 [==============================] - 14s 75ms/step - loss: -1028.1688 - accuracy: 0.6499 - val_loss: -647.6865 - val_accuracy: 0.5082\n",
      "Epoch 143/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -1031.0093 - accuracy: 0.6499 - val_loss: -648.5502 - val_accuracy: 0.5128\n",
      "Epoch 144/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -1039.9271 - accuracy: 0.6496 - val_loss: -657.1211 - val_accuracy: 0.5141\n",
      "Epoch 145/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1048.2291 - accuracy: 0.6529 - val_loss: -657.6817 - val_accuracy: 0.5174\n",
      "Epoch 146/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -1057.4564 - accuracy: 0.6519 - val_loss: -660.2662 - val_accuracy: 0.5161\n",
      "Epoch 147/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -1063.8251 - accuracy: 0.6509 - val_loss: -665.6437 - val_accuracy: 0.5128\n",
      "Epoch 148/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -1071.9199 - accuracy: 0.6524 - val_loss: -674.3563 - val_accuracy: 0.5154\n",
      "Epoch 149/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -1074.7367 - accuracy: 0.6508 - val_loss: -669.3938 - val_accuracy: 0.5213\n",
      "Epoch 150/500\n",
      "191/191 [==============================] - 16s 82ms/step - loss: -1084.2374 - accuracy: 0.6522 - val_loss: -673.5911 - val_accuracy: 0.5193\n",
      "Epoch 151/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1093.4772 - accuracy: 0.6537 - val_loss: -674.0022 - val_accuracy: 0.5134\n",
      "Epoch 152/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -1100.5698 - accuracy: 0.6552 - val_loss: -682.2304 - val_accuracy: 0.5128\n",
      "Epoch 153/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1106.6488 - accuracy: 0.6503 - val_loss: -691.0728 - val_accuracy: 0.5069\n",
      "Epoch 154/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -1114.7754 - accuracy: 0.6506 - val_loss: -687.8485 - val_accuracy: 0.5108\n",
      "Epoch 155/500\n",
      "191/191 [==============================] - 14s 75ms/step - loss: -1120.2322 - accuracy: 0.6522 - val_loss: -706.7763 - val_accuracy: 0.5121\n",
      "Epoch 156/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1126.2665 - accuracy: 0.6458 - val_loss: -693.5917 - val_accuracy: 0.5069\n",
      "Epoch 157/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1135.1812 - accuracy: 0.6494 - val_loss: -704.9919 - val_accuracy: 0.5134\n",
      "Epoch 158/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1144.1918 - accuracy: 0.6519 - val_loss: -712.8591 - val_accuracy: 0.5128\n",
      "Epoch 159/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1153.0530 - accuracy: 0.6531 - val_loss: -712.6036 - val_accuracy: 0.5154\n",
      "Epoch 160/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1156.0227 - accuracy: 0.6490 - val_loss: -716.2542 - val_accuracy: 0.5121\n",
      "Epoch 161/500\n",
      "191/191 [==============================] - 14s 76ms/step - loss: -1163.5989 - accuracy: 0.6512 - val_loss: -726.3149 - val_accuracy: 0.5102\n",
      "Epoch 162/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -1171.8286 - accuracy: 0.6550 - val_loss: -728.6948 - val_accuracy: 0.5108\n",
      "Epoch 163/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1181.2188 - accuracy: 0.6558 - val_loss: -728.5496 - val_accuracy: 0.5148\n",
      "Epoch 164/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -1185.5732 - accuracy: 0.6527 - val_loss: -726.6654 - val_accuracy: 0.5134\n",
      "Epoch 165/500\n",
      "191/191 [==============================] - 15s 81ms/step - loss: -1192.8682 - accuracy: 0.6552 - val_loss: -722.1771 - val_accuracy: 0.5082\n",
      "Epoch 166/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -1201.9937 - accuracy: 0.6573 - val_loss: -752.2405 - val_accuracy: 0.5134\n",
      "Epoch 167/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -1210.6737 - accuracy: 0.6547 - val_loss: -734.0569 - val_accuracy: 0.5167\n",
      "Epoch 168/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1212.4946 - accuracy: 0.6444 - val_loss: -745.3471 - val_accuracy: 0.5128\n",
      "Epoch 169/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -1219.9001 - accuracy: 0.6496 - val_loss: -745.0223 - val_accuracy: 0.5108\n",
      "Epoch 170/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1231.0739 - accuracy: 0.6565 - val_loss: -758.0137 - val_accuracy: 0.5193\n",
      "Epoch 171/500\n",
      "191/191 [==============================] - 16s 85ms/step - loss: -1236.6688 - accuracy: 0.6535 - val_loss: -761.4014 - val_accuracy: 0.5161\n",
      "Epoch 172/500\n",
      "191/191 [==============================] - 16s 86ms/step - loss: -1243.5637 - accuracy: 0.6529 - val_loss: -768.2116 - val_accuracy: 0.5141\n",
      "Epoch 173/500\n",
      "191/191 [==============================] - 16s 85ms/step - loss: -1254.5239 - accuracy: 0.6549 - val_loss: -768.5720 - val_accuracy: 0.5174\n",
      "Epoch 174/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1260.4550 - accuracy: 0.6524 - val_loss: -785.0528 - val_accuracy: 0.5115\n",
      "Epoch 175/500\n",
      "191/191 [==============================] - 16s 84ms/step - loss: -1268.5406 - accuracy: 0.6535 - val_loss: -785.7059 - val_accuracy: 0.5187\n",
      "Epoch 176/500\n",
      "191/191 [==============================] - 16s 83ms/step - loss: -1275.3064 - accuracy: 0.6565 - val_loss: -781.9016 - val_accuracy: 0.5200\n",
      "Epoch 177/500\n",
      "191/191 [==============================] - 15s 81ms/step - loss: -1282.6177 - accuracy: 0.6521 - val_loss: -800.4139 - val_accuracy: 0.5233\n",
      "Epoch 178/500\n",
      "191/191 [==============================] - 15s 81ms/step - loss: -1287.7274 - accuracy: 0.6549 - val_loss: -796.2391 - val_accuracy: 0.5148\n",
      "Epoch 179/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -1295.7496 - accuracy: 0.6540 - val_loss: -809.0651 - val_accuracy: 0.5141\n",
      "Epoch 180/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1305.4677 - accuracy: 0.6565 - val_loss: -807.5718 - val_accuracy: 0.5200\n",
      "Epoch 181/500\n",
      "191/191 [==============================] - 14s 76ms/step - loss: -1306.6853 - accuracy: 0.6565 - val_loss: -810.9453 - val_accuracy: 0.5200\n",
      "Epoch 182/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1318.0524 - accuracy: 0.6567 - val_loss: -817.7392 - val_accuracy: 0.5200\n",
      "Epoch 183/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1327.2181 - accuracy: 0.6542 - val_loss: -827.0753 - val_accuracy: 0.5207\n",
      "Epoch 184/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1332.8167 - accuracy: 0.6547 - val_loss: -832.0939 - val_accuracy: 0.5207\n",
      "Epoch 185/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1338.2499 - accuracy: 0.6558 - val_loss: -824.3610 - val_accuracy: 0.5154\n",
      "Epoch 186/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1347.1084 - accuracy: 0.6572 - val_loss: -837.1758 - val_accuracy: 0.5102\n",
      "Epoch 187/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1349.0856 - accuracy: 0.6555 - val_loss: -831.8848 - val_accuracy: 0.5128\n",
      "Epoch 188/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -1362.1161 - accuracy: 0.6568 - val_loss: -842.5733 - val_accuracy: 0.5069\n",
      "Epoch 189/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -1365.6082 - accuracy: 0.6557 - val_loss: -846.6439 - val_accuracy: 0.5095\n",
      "Epoch 190/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1373.2943 - accuracy: 0.6527 - val_loss: -845.8260 - val_accuracy: 0.5075\n",
      "Epoch 191/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1384.1053 - accuracy: 0.6555 - val_loss: -861.2146 - val_accuracy: 0.5102\n",
      "Epoch 192/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -1384.8555 - accuracy: 0.6516 - val_loss: -859.4065 - val_accuracy: 0.4997\n",
      "Epoch 193/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1393.5812 - accuracy: 0.6519 - val_loss: -862.6270 - val_accuracy: 0.5056\n",
      "Epoch 194/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -1401.3798 - accuracy: 0.6545 - val_loss: -868.5779 - val_accuracy: 0.5030\n",
      "Epoch 195/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -1410.6151 - accuracy: 0.6501 - val_loss: -872.3862 - val_accuracy: 0.5062\n",
      "Epoch 196/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1415.7146 - accuracy: 0.6490 - val_loss: -876.4080 - val_accuracy: 0.5049\n",
      "Epoch 197/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1424.3726 - accuracy: 0.6508 - val_loss: -877.3527 - val_accuracy: 0.5062\n",
      "Epoch 198/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1433.4047 - accuracy: 0.6560 - val_loss: -869.4926 - val_accuracy: 0.5121\n",
      "Epoch 199/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1441.4647 - accuracy: 0.6562 - val_loss: -881.0492 - val_accuracy: 0.5134\n",
      "Epoch 200/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1446.4331 - accuracy: 0.6549 - val_loss: -883.3549 - val_accuracy: 0.5056\n",
      "Epoch 201/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1456.7018 - accuracy: 0.6575 - val_loss: -900.1216 - val_accuracy: 0.5082\n",
      "Epoch 202/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -1460.7761 - accuracy: 0.6562 - val_loss: -914.9291 - val_accuracy: 0.5108\n",
      "Epoch 203/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1470.7048 - accuracy: 0.6586 - val_loss: -918.2885 - val_accuracy: 0.5108\n",
      "Epoch 204/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1479.2976 - accuracy: 0.6575 - val_loss: -929.7689 - val_accuracy: 0.5089\n",
      "Epoch 205/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -1487.3806 - accuracy: 0.6580 - val_loss: -939.2564 - val_accuracy: 0.5089\n",
      "Epoch 206/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -1494.1661 - accuracy: 0.6617 - val_loss: -941.5812 - val_accuracy: 0.5121\n",
      "Epoch 207/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1500.2976 - accuracy: 0.6632 - val_loss: -940.5626 - val_accuracy: 0.5154\n",
      "Epoch 208/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -1508.7344 - accuracy: 0.6591 - val_loss: -949.5906 - val_accuracy: 0.5148\n",
      "Epoch 209/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1518.1322 - accuracy: 0.6588 - val_loss: -939.9020 - val_accuracy: 0.5108\n",
      "Epoch 210/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1526.1569 - accuracy: 0.6624 - val_loss: -949.9419 - val_accuracy: 0.5154\n",
      "Epoch 211/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1530.4700 - accuracy: 0.6606 - val_loss: -964.1893 - val_accuracy: 0.5148\n",
      "Epoch 212/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1537.8860 - accuracy: 0.6616 - val_loss: -959.1027 - val_accuracy: 0.5128\n",
      "Epoch 213/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1545.8649 - accuracy: 0.6631 - val_loss: -961.2886 - val_accuracy: 0.5075\n",
      "Epoch 214/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -1553.0295 - accuracy: 0.6613 - val_loss: -975.0270 - val_accuracy: 0.5082\n",
      "Epoch 215/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -1559.8550 - accuracy: 0.6604 - val_loss: -1004.0161 - val_accuracy: 0.5089\n",
      "Epoch 216/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1568.6321 - accuracy: 0.6586 - val_loss: -1003.4890 - val_accuracy: 0.5082\n",
      "Epoch 217/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1573.1293 - accuracy: 0.6593 - val_loss: -995.9536 - val_accuracy: 0.5108\n",
      "Epoch 218/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -1581.8098 - accuracy: 0.6611 - val_loss: -954.4906 - val_accuracy: 0.5062\n",
      "Epoch 219/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -1587.4226 - accuracy: 0.6583 - val_loss: -999.9553 - val_accuracy: 0.5115\n",
      "Epoch 220/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1597.5300 - accuracy: 0.6599 - val_loss: -995.8336 - val_accuracy: 0.5128\n",
      "Epoch 221/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1605.5726 - accuracy: 0.6629 - val_loss: -1009.8757 - val_accuracy: 0.5161\n",
      "Epoch 222/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -1610.3436 - accuracy: 0.6614 - val_loss: -1018.1744 - val_accuracy: 0.5121\n",
      "Epoch 223/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1620.9756 - accuracy: 0.6604 - val_loss: -1016.6958 - val_accuracy: 0.5062\n",
      "Epoch 224/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1626.2389 - accuracy: 0.6621 - val_loss: -1017.3743 - val_accuracy: 0.5049\n",
      "Epoch 225/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1636.5679 - accuracy: 0.6621 - val_loss: -1010.2970 - val_accuracy: 0.5075\n",
      "Epoch 226/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1643.0264 - accuracy: 0.6629 - val_loss: -1037.2001 - val_accuracy: 0.5148\n",
      "Epoch 227/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1648.4769 - accuracy: 0.6619 - val_loss: -1030.2255 - val_accuracy: 0.5062\n",
      "Epoch 228/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -1655.9757 - accuracy: 0.6611 - val_loss: -1039.7036 - val_accuracy: 0.5095\n",
      "Epoch 229/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1662.0946 - accuracy: 0.6624 - val_loss: -1049.7578 - val_accuracy: 0.5141\n",
      "Epoch 230/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -1670.2096 - accuracy: 0.6586 - val_loss: -1053.1962 - val_accuracy: 0.5121\n",
      "Epoch 231/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1677.7791 - accuracy: 0.6629 - val_loss: -1052.3761 - val_accuracy: 0.5108\n",
      "Epoch 232/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1680.8788 - accuracy: 0.6616 - val_loss: -1062.2200 - val_accuracy: 0.5102\n",
      "Epoch 233/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1689.1941 - accuracy: 0.6640 - val_loss: -1053.9119 - val_accuracy: 0.5134\n",
      "Epoch 234/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -1699.1373 - accuracy: 0.6627 - val_loss: -1064.3752 - val_accuracy: 0.5121\n",
      "Epoch 235/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -1704.2758 - accuracy: 0.6619 - val_loss: -1044.0399 - val_accuracy: 0.5187\n",
      "Epoch 236/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1701.0924 - accuracy: 0.6547 - val_loss: -1077.0745 - val_accuracy: 0.5128\n",
      "Epoch 237/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1716.5753 - accuracy: 0.6560 - val_loss: -1080.1997 - val_accuracy: 0.5095\n",
      "Epoch 238/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1728.1201 - accuracy: 0.6590 - val_loss: -1088.3762 - val_accuracy: 0.5115\n",
      "Epoch 239/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1731.9943 - accuracy: 0.6578 - val_loss: -1072.1398 - val_accuracy: 0.5141\n",
      "Epoch 240/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1740.9462 - accuracy: 0.6593 - val_loss: -1109.8074 - val_accuracy: 0.5102\n",
      "Epoch 241/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -1746.5730 - accuracy: 0.6609 - val_loss: -1097.1404 - val_accuracy: 0.5174\n",
      "Epoch 242/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1758.6622 - accuracy: 0.6581 - val_loss: -1105.0292 - val_accuracy: 0.5154\n",
      "Epoch 243/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1765.2856 - accuracy: 0.6631 - val_loss: -1106.8254 - val_accuracy: 0.5161\n",
      "Epoch 244/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1769.2943 - accuracy: 0.6609 - val_loss: -1108.3682 - val_accuracy: 0.5161\n",
      "Epoch 245/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1778.9852 - accuracy: 0.6616 - val_loss: -1123.0762 - val_accuracy: 0.5200\n",
      "Epoch 246/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -1789.7733 - accuracy: 0.6626 - val_loss: -1128.9277 - val_accuracy: 0.5180\n",
      "Epoch 247/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -1796.9146 - accuracy: 0.6634 - val_loss: -1130.2247 - val_accuracy: 0.5161\n",
      "Epoch 248/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -1800.0961 - accuracy: 0.6613 - val_loss: -1125.8273 - val_accuracy: 0.5246\n",
      "Epoch 249/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1809.4828 - accuracy: 0.6594 - val_loss: -1139.7374 - val_accuracy: 0.5180\n",
      "Epoch 250/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1812.4255 - accuracy: 0.6596 - val_loss: -1103.3994 - val_accuracy: 0.5193\n",
      "Epoch 251/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1817.2758 - accuracy: 0.6580 - val_loss: -1122.4633 - val_accuracy: 0.5180\n",
      "Epoch 252/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -1829.9822 - accuracy: 0.6617 - val_loss: -1129.8467 - val_accuracy: 0.5167\n",
      "Epoch 253/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1837.3708 - accuracy: 0.6590 - val_loss: -1144.4901 - val_accuracy: 0.5200\n",
      "Epoch 254/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -1843.9863 - accuracy: 0.6549 - val_loss: -1159.1448 - val_accuracy: 0.5193\n",
      "Epoch 255/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -1852.8645 - accuracy: 0.6635 - val_loss: -1162.3634 - val_accuracy: 0.5128\n",
      "Epoch 256/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -1859.4164 - accuracy: 0.6598 - val_loss: -1152.8295 - val_accuracy: 0.5095\n",
      "Epoch 257/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1864.9033 - accuracy: 0.6629 - val_loss: -1193.2393 - val_accuracy: 0.5174\n",
      "Epoch 258/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1876.1034 - accuracy: 0.6581 - val_loss: -1198.5505 - val_accuracy: 0.5213\n",
      "Epoch 259/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -1882.7749 - accuracy: 0.6624 - val_loss: -1191.0977 - val_accuracy: 0.5233\n",
      "Epoch 260/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1891.7354 - accuracy: 0.6647 - val_loss: -1192.3479 - val_accuracy: 0.5213\n",
      "Epoch 261/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -1899.5044 - accuracy: 0.6635 - val_loss: -1188.3665 - val_accuracy: 0.5226\n",
      "Epoch 262/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1905.0953 - accuracy: 0.6637 - val_loss: -1202.7292 - val_accuracy: 0.5220\n",
      "Epoch 263/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -1911.6368 - accuracy: 0.6634 - val_loss: -1195.2577 - val_accuracy: 0.5226\n",
      "Epoch 264/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1921.4834 - accuracy: 0.6657 - val_loss: -1219.1519 - val_accuracy: 0.5252\n",
      "Epoch 265/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -1923.9427 - accuracy: 0.6608 - val_loss: -1219.4559 - val_accuracy: 0.5259\n",
      "Epoch 266/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -1931.6426 - accuracy: 0.6635 - val_loss: -1206.0427 - val_accuracy: 0.5200\n",
      "Epoch 267/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -1936.7969 - accuracy: 0.6640 - val_loss: -1192.5764 - val_accuracy: 0.5220\n",
      "Epoch 268/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -1945.8755 - accuracy: 0.6606 - val_loss: -1147.9856 - val_accuracy: 0.5207\n",
      "Epoch 269/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1949.9384 - accuracy: 0.6617 - val_loss: -1203.1265 - val_accuracy: 0.5292\n",
      "Epoch 270/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -1959.0249 - accuracy: 0.6601 - val_loss: -1209.2823 - val_accuracy: 0.5246\n",
      "Epoch 271/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1967.4781 - accuracy: 0.6629 - val_loss: -1221.2383 - val_accuracy: 0.5233\n",
      "Epoch 272/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1979.0444 - accuracy: 0.6634 - val_loss: -1222.2937 - val_accuracy: 0.5239\n",
      "Epoch 273/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -1981.6886 - accuracy: 0.6640 - val_loss: -1230.6117 - val_accuracy: 0.5239\n",
      "Epoch 274/500\n",
      "191/191 [==============================] - 14s 76ms/step - loss: -1991.6649 - accuracy: 0.6677 - val_loss: -1231.5759 - val_accuracy: 0.5226\n",
      "Epoch 275/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -1994.5662 - accuracy: 0.6629 - val_loss: -1228.7639 - val_accuracy: 0.5233\n",
      "Epoch 276/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2003.8406 - accuracy: 0.6652 - val_loss: -1232.6842 - val_accuracy: 0.5285\n",
      "Epoch 277/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2012.8289 - accuracy: 0.6675 - val_loss: -1236.9607 - val_accuracy: 0.5180\n",
      "Epoch 278/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2020.6780 - accuracy: 0.6622 - val_loss: -1248.6736 - val_accuracy: 0.5226\n",
      "Epoch 279/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2027.0391 - accuracy: 0.6691 - val_loss: -1250.7719 - val_accuracy: 0.5233\n",
      "Epoch 280/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2035.0018 - accuracy: 0.6654 - val_loss: -1253.5070 - val_accuracy: 0.5213\n",
      "Epoch 281/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2045.3301 - accuracy: 0.6685 - val_loss: -1268.8741 - val_accuracy: 0.5180\n",
      "Epoch 282/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2053.5513 - accuracy: 0.6662 - val_loss: -1265.3199 - val_accuracy: 0.5207\n",
      "Epoch 283/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -2057.6104 - accuracy: 0.6693 - val_loss: -1272.1646 - val_accuracy: 0.5207\n",
      "Epoch 284/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2068.5259 - accuracy: 0.6672 - val_loss: -1290.7040 - val_accuracy: 0.5193\n",
      "Epoch 285/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2074.5002 - accuracy: 0.6619 - val_loss: -1283.5010 - val_accuracy: 0.5193\n",
      "Epoch 286/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2077.3909 - accuracy: 0.6673 - val_loss: -1262.5819 - val_accuracy: 0.5174\n",
      "Epoch 287/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2084.9556 - accuracy: 0.6642 - val_loss: -1300.4200 - val_accuracy: 0.5167\n",
      "Epoch 288/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2095.0549 - accuracy: 0.6673 - val_loss: -1317.7721 - val_accuracy: 0.5187\n",
      "Epoch 289/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2104.4128 - accuracy: 0.6649 - val_loss: -1315.9685 - val_accuracy: 0.5213\n",
      "Epoch 290/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2109.3110 - accuracy: 0.6658 - val_loss: -1303.3616 - val_accuracy: 0.5239\n",
      "Epoch 291/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2116.2207 - accuracy: 0.6668 - val_loss: -1327.5951 - val_accuracy: 0.5252\n",
      "Epoch 292/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2125.0845 - accuracy: 0.6657 - val_loss: -1343.9686 - val_accuracy: 0.5239\n",
      "Epoch 293/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2133.3948 - accuracy: 0.6673 - val_loss: -1353.2515 - val_accuracy: 0.5272\n",
      "Epoch 294/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -2141.8892 - accuracy: 0.6670 - val_loss: -1343.3995 - val_accuracy: 0.5246\n",
      "Epoch 295/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2148.2249 - accuracy: 0.6678 - val_loss: -1358.2582 - val_accuracy: 0.5279\n",
      "Epoch 296/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2152.6372 - accuracy: 0.6649 - val_loss: -1359.8730 - val_accuracy: 0.5279\n",
      "Epoch 297/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2163.5803 - accuracy: 0.6686 - val_loss: -1358.6587 - val_accuracy: 0.5298\n",
      "Epoch 298/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2169.1506 - accuracy: 0.6678 - val_loss: -1358.1158 - val_accuracy: 0.5266\n",
      "Epoch 299/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2178.4746 - accuracy: 0.6678 - val_loss: -1385.9729 - val_accuracy: 0.5272\n",
      "Epoch 300/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2182.7991 - accuracy: 0.6668 - val_loss: -1366.2050 - val_accuracy: 0.5220\n",
      "Epoch 301/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2188.4983 - accuracy: 0.6652 - val_loss: -1377.3147 - val_accuracy: 0.5233\n",
      "Epoch 302/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2198.1921 - accuracy: 0.6658 - val_loss: -1394.6493 - val_accuracy: 0.5161\n",
      "Epoch 303/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -2206.8271 - accuracy: 0.6655 - val_loss: -1396.1373 - val_accuracy: 0.5207\n",
      "Epoch 304/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2207.0164 - accuracy: 0.6650 - val_loss: -1368.6992 - val_accuracy: 0.5180\n",
      "Epoch 305/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -2216.0088 - accuracy: 0.6677 - val_loss: -1385.1190 - val_accuracy: 0.5154\n",
      "Epoch 306/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2226.2964 - accuracy: 0.6680 - val_loss: -1397.3231 - val_accuracy: 0.5213\n",
      "Epoch 307/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2235.3992 - accuracy: 0.6683 - val_loss: -1389.9713 - val_accuracy: 0.5239\n",
      "Epoch 308/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2244.9482 - accuracy: 0.6696 - val_loss: -1410.2526 - val_accuracy: 0.5246\n",
      "Epoch 309/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2248.8779 - accuracy: 0.6704 - val_loss: -1391.7548 - val_accuracy: 0.5239\n",
      "Epoch 310/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -2253.1379 - accuracy: 0.6652 - val_loss: -1372.4742 - val_accuracy: 0.5246\n",
      "Epoch 311/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2257.3870 - accuracy: 0.6668 - val_loss: -1396.3204 - val_accuracy: 0.5174\n",
      "Epoch 312/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -2269.1294 - accuracy: 0.6657 - val_loss: -1385.1416 - val_accuracy: 0.5246\n",
      "Epoch 313/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2273.1299 - accuracy: 0.6654 - val_loss: -1385.0316 - val_accuracy: 0.5187\n",
      "Epoch 314/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2282.5879 - accuracy: 0.6685 - val_loss: -1363.5417 - val_accuracy: 0.5226\n",
      "Epoch 315/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2283.2883 - accuracy: 0.6663 - val_loss: -1411.3706 - val_accuracy: 0.5213\n",
      "Epoch 316/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2296.9539 - accuracy: 0.6677 - val_loss: -1412.3777 - val_accuracy: 0.5213\n",
      "Epoch 317/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2306.6243 - accuracy: 0.6655 - val_loss: -1418.1577 - val_accuracy: 0.5239\n",
      "Epoch 318/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2315.0684 - accuracy: 0.6670 - val_loss: -1431.9236 - val_accuracy: 0.5207\n",
      "Epoch 319/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2319.7463 - accuracy: 0.6645 - val_loss: -1423.0923 - val_accuracy: 0.5246\n",
      "Epoch 320/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2323.3335 - accuracy: 0.6629 - val_loss: -1455.0364 - val_accuracy: 0.5233\n",
      "Epoch 321/500\n",
      "191/191 [==============================] - 14s 76ms/step - loss: -2331.1768 - accuracy: 0.6640 - val_loss: -1483.9113 - val_accuracy: 0.5213\n",
      "Epoch 322/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2341.9233 - accuracy: 0.6637 - val_loss: -1455.1863 - val_accuracy: 0.5252\n",
      "Epoch 323/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2348.2952 - accuracy: 0.6695 - val_loss: -1465.3679 - val_accuracy: 0.5193\n",
      "Epoch 324/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2353.0757 - accuracy: 0.6647 - val_loss: -1469.1089 - val_accuracy: 0.5266\n",
      "Epoch 325/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2364.4563 - accuracy: 0.6691 - val_loss: -1478.6271 - val_accuracy: 0.5259\n",
      "Epoch 326/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2374.7166 - accuracy: 0.6681 - val_loss: -1459.4994 - val_accuracy: 0.5259\n",
      "Epoch 327/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2379.4802 - accuracy: 0.6622 - val_loss: -1481.1711 - val_accuracy: 0.5298\n",
      "Epoch 328/500\n",
      "191/191 [==============================] - 14s 76ms/step - loss: -2389.5515 - accuracy: 0.6693 - val_loss: -1481.9354 - val_accuracy: 0.5311\n",
      "Epoch 329/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2392.9495 - accuracy: 0.6655 - val_loss: -1478.2931 - val_accuracy: 0.5285\n",
      "Epoch 330/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2397.8208 - accuracy: 0.6665 - val_loss: -1485.1190 - val_accuracy: 0.5279\n",
      "Epoch 331/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2407.5637 - accuracy: 0.6703 - val_loss: -1463.6129 - val_accuracy: 0.5246\n",
      "Epoch 332/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2414.1716 - accuracy: 0.6654 - val_loss: -1494.9971 - val_accuracy: 0.5220\n",
      "Epoch 333/500\n",
      "191/191 [==============================] - 14s 76ms/step - loss: -2420.7832 - accuracy: 0.6631 - val_loss: -1514.2396 - val_accuracy: 0.5193\n",
      "Epoch 334/500\n",
      "191/191 [==============================] - 14s 75ms/step - loss: -2426.2920 - accuracy: 0.6631 - val_loss: -1502.5630 - val_accuracy: 0.5174\n",
      "Epoch 335/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2430.0222 - accuracy: 0.6645 - val_loss: -1459.6583 - val_accuracy: 0.5272\n",
      "Epoch 336/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2446.6848 - accuracy: 0.6681 - val_loss: -1512.9358 - val_accuracy: 0.5266\n",
      "Epoch 337/500\n",
      "191/191 [==============================] - 16s 82ms/step - loss: -2453.3823 - accuracy: 0.6660 - val_loss: -1528.5750 - val_accuracy: 0.5246\n",
      "Epoch 338/500\n",
      "191/191 [==============================] - 16s 84ms/step - loss: -2456.8179 - accuracy: 0.6634 - val_loss: -1525.9513 - val_accuracy: 0.5298\n",
      "Epoch 339/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -2461.5583 - accuracy: 0.6654 - val_loss: -1537.4802 - val_accuracy: 0.5252\n",
      "Epoch 340/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -2474.9487 - accuracy: 0.6667 - val_loss: -1534.8699 - val_accuracy: 0.5233\n",
      "Epoch 341/500\n",
      "191/191 [==============================] - 14s 75ms/step - loss: -2481.7952 - accuracy: 0.6665 - val_loss: -1547.6683 - val_accuracy: 0.5285\n",
      "Epoch 342/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2488.9531 - accuracy: 0.6673 - val_loss: -1552.0535 - val_accuracy: 0.5266\n",
      "Epoch 343/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2494.4714 - accuracy: 0.6658 - val_loss: -1539.9967 - val_accuracy: 0.5259\n",
      "Epoch 344/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2505.8008 - accuracy: 0.6690 - val_loss: -1531.4729 - val_accuracy: 0.5233\n",
      "Epoch 345/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2510.8181 - accuracy: 0.6691 - val_loss: -1565.2931 - val_accuracy: 0.5252\n",
      "Epoch 346/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -2520.7034 - accuracy: 0.6677 - val_loss: -1565.6675 - val_accuracy: 0.5233\n",
      "Epoch 347/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -2519.8508 - accuracy: 0.6616 - val_loss: -1544.2693 - val_accuracy: 0.5187\n",
      "Epoch 348/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2530.4683 - accuracy: 0.6639 - val_loss: -1572.4126 - val_accuracy: 0.5226\n",
      "Epoch 349/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2543.3528 - accuracy: 0.6667 - val_loss: -1582.0503 - val_accuracy: 0.5207\n",
      "Epoch 350/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2543.9700 - accuracy: 0.6652 - val_loss: -1561.5033 - val_accuracy: 0.5246\n",
      "Epoch 351/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2558.9626 - accuracy: 0.6691 - val_loss: -1571.2222 - val_accuracy: 0.5207\n",
      "Epoch 352/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2563.9329 - accuracy: 0.6698 - val_loss: -1583.4729 - val_accuracy: 0.5213\n",
      "Epoch 353/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2571.7468 - accuracy: 0.6695 - val_loss: -1579.1472 - val_accuracy: 0.5246\n",
      "Epoch 354/500\n",
      "191/191 [==============================] - 14s 76ms/step - loss: -2575.8943 - accuracy: 0.6668 - val_loss: -1592.2582 - val_accuracy: 0.5226\n",
      "Epoch 355/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -2580.2993 - accuracy: 0.6665 - val_loss: -1569.6172 - val_accuracy: 0.5187\n",
      "Epoch 356/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2593.0598 - accuracy: 0.6680 - val_loss: -1585.2881 - val_accuracy: 0.5207\n",
      "Epoch 357/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2601.2778 - accuracy: 0.6637 - val_loss: -1574.9690 - val_accuracy: 0.5180\n",
      "Epoch 358/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2607.6138 - accuracy: 0.6677 - val_loss: -1589.2668 - val_accuracy: 0.5213\n",
      "Epoch 359/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2617.1646 - accuracy: 0.6695 - val_loss: -1592.6764 - val_accuracy: 0.5233\n",
      "Epoch 360/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2623.5071 - accuracy: 0.6711 - val_loss: -1618.3097 - val_accuracy: 0.5213\n",
      "Epoch 361/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2626.6733 - accuracy: 0.6652 - val_loss: -1602.0311 - val_accuracy: 0.5311\n",
      "Epoch 362/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2625.2842 - accuracy: 0.6614 - val_loss: -1647.0231 - val_accuracy: 0.5220\n",
      "Epoch 363/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2635.5337 - accuracy: 0.6644 - val_loss: -1616.7394 - val_accuracy: 0.5246\n",
      "Epoch 364/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2643.1721 - accuracy: 0.6691 - val_loss: -1615.5713 - val_accuracy: 0.5266\n",
      "Epoch 365/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2653.2510 - accuracy: 0.6658 - val_loss: -1623.4098 - val_accuracy: 0.5252\n",
      "Epoch 366/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2665.3428 - accuracy: 0.6677 - val_loss: -1623.1005 - val_accuracy: 0.5259\n",
      "Epoch 367/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2671.8677 - accuracy: 0.6660 - val_loss: -1637.6501 - val_accuracy: 0.5233\n",
      "Epoch 368/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2680.3547 - accuracy: 0.6658 - val_loss: -1630.1268 - val_accuracy: 0.5266\n",
      "Epoch 369/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2683.6265 - accuracy: 0.6677 - val_loss: -1631.3623 - val_accuracy: 0.5305\n",
      "Epoch 370/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2695.3923 - accuracy: 0.6652 - val_loss: -1660.3295 - val_accuracy: 0.5318\n",
      "Epoch 371/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2693.4951 - accuracy: 0.6663 - val_loss: -1643.7515 - val_accuracy: 0.5311\n",
      "Epoch 372/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2706.7903 - accuracy: 0.6668 - val_loss: -1682.6655 - val_accuracy: 0.5311\n",
      "Epoch 373/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -2716.0120 - accuracy: 0.6663 - val_loss: -1681.7319 - val_accuracy: 0.5272\n",
      "Epoch 374/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2711.8333 - accuracy: 0.6655 - val_loss: -1705.7252 - val_accuracy: 0.5207\n",
      "Epoch 375/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2728.5715 - accuracy: 0.6675 - val_loss: -1710.4069 - val_accuracy: 0.5167\n",
      "Epoch 376/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2736.1572 - accuracy: 0.6681 - val_loss: -1718.4619 - val_accuracy: 0.5213\n",
      "Epoch 377/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2738.9673 - accuracy: 0.6657 - val_loss: -1707.7883 - val_accuracy: 0.5187\n",
      "Epoch 378/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2750.9966 - accuracy: 0.6688 - val_loss: -1720.1973 - val_accuracy: 0.5220\n",
      "Epoch 379/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2760.6462 - accuracy: 0.6708 - val_loss: -1719.3582 - val_accuracy: 0.5233\n",
      "Epoch 380/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2767.9497 - accuracy: 0.6696 - val_loss: -1692.2078 - val_accuracy: 0.5220\n",
      "Epoch 381/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -2773.1936 - accuracy: 0.6681 - val_loss: -1699.8792 - val_accuracy: 0.5226\n",
      "Epoch 382/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2783.1982 - accuracy: 0.6690 - val_loss: -1716.0837 - val_accuracy: 0.5239\n",
      "Epoch 383/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2789.9172 - accuracy: 0.6703 - val_loss: -1726.3741 - val_accuracy: 0.5259\n",
      "Epoch 384/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2799.0767 - accuracy: 0.6714 - val_loss: -1728.5610 - val_accuracy: 0.5298\n",
      "Epoch 385/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2805.2188 - accuracy: 0.6673 - val_loss: -1716.1492 - val_accuracy: 0.5272\n",
      "Epoch 386/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2817.0518 - accuracy: 0.6713 - val_loss: -1760.5310 - val_accuracy: 0.5259\n",
      "Epoch 387/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2817.2898 - accuracy: 0.6716 - val_loss: -1762.2437 - val_accuracy: 0.5311\n",
      "Epoch 388/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2819.9302 - accuracy: 0.6673 - val_loss: -1747.3866 - val_accuracy: 0.5272\n",
      "Epoch 389/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2835.4409 - accuracy: 0.6718 - val_loss: -1776.0450 - val_accuracy: 0.5292\n",
      "Epoch 390/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2846.1431 - accuracy: 0.6719 - val_loss: -1788.9113 - val_accuracy: 0.5292\n",
      "Epoch 391/500\n",
      "191/191 [==============================] - 16s 81ms/step - loss: -2852.0525 - accuracy: 0.6681 - val_loss: -1797.0757 - val_accuracy: 0.5266\n",
      "Epoch 392/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2855.1995 - accuracy: 0.6698 - val_loss: -1792.8964 - val_accuracy: 0.5338\n",
      "Epoch 393/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2866.9526 - accuracy: 0.6698 - val_loss: -1805.9243 - val_accuracy: 0.5318\n",
      "Epoch 394/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -2871.3218 - accuracy: 0.6709 - val_loss: -1779.8002 - val_accuracy: 0.5272\n",
      "Epoch 395/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -2882.4822 - accuracy: 0.6714 - val_loss: -1766.1798 - val_accuracy: 0.5259\n",
      "Epoch 396/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2876.1873 - accuracy: 0.6703 - val_loss: -1759.1080 - val_accuracy: 0.5285\n",
      "Epoch 397/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -2888.3330 - accuracy: 0.6678 - val_loss: -1781.9714 - val_accuracy: 0.5207\n",
      "Epoch 398/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2900.4822 - accuracy: 0.6706 - val_loss: -1759.6797 - val_accuracy: 0.5226\n",
      "Epoch 399/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2909.8989 - accuracy: 0.6683 - val_loss: -1783.4762 - val_accuracy: 0.5213\n",
      "Epoch 400/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2914.9172 - accuracy: 0.6675 - val_loss: -1780.0211 - val_accuracy: 0.5207\n",
      "Epoch 401/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -2923.7942 - accuracy: 0.6686 - val_loss: -1788.6177 - val_accuracy: 0.5220\n",
      "Epoch 402/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2931.0894 - accuracy: 0.6695 - val_loss: -1810.3776 - val_accuracy: 0.5213\n",
      "Epoch 403/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2936.0154 - accuracy: 0.6675 - val_loss: -1805.6691 - val_accuracy: 0.5213\n",
      "Epoch 404/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2943.2122 - accuracy: 0.6722 - val_loss: -1802.4994 - val_accuracy: 0.5226\n",
      "Epoch 405/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -2954.1929 - accuracy: 0.6737 - val_loss: -1805.6515 - val_accuracy: 0.5226\n",
      "Epoch 406/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -2957.3474 - accuracy: 0.6711 - val_loss: -1798.6949 - val_accuracy: 0.5239\n",
      "Epoch 407/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2962.9182 - accuracy: 0.6688 - val_loss: -1816.9679 - val_accuracy: 0.5259\n",
      "Epoch 408/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -2975.0408 - accuracy: 0.6708 - val_loss: -1824.8307 - val_accuracy: 0.5266\n",
      "Epoch 409/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -2983.3730 - accuracy: 0.6726 - val_loss: -1822.5153 - val_accuracy: 0.5259\n",
      "Epoch 410/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -2988.1411 - accuracy: 0.6686 - val_loss: -1833.0359 - val_accuracy: 0.5207\n",
      "Epoch 411/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3002.0708 - accuracy: 0.6714 - val_loss: -1818.5872 - val_accuracy: 0.5200\n",
      "Epoch 412/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3005.5784 - accuracy: 0.6704 - val_loss: -1838.6572 - val_accuracy: 0.5246\n",
      "Epoch 413/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -3007.9648 - accuracy: 0.6724 - val_loss: -1848.1785 - val_accuracy: 0.5220\n",
      "Epoch 414/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -3019.1104 - accuracy: 0.6696 - val_loss: -1830.2164 - val_accuracy: 0.5279\n",
      "Epoch 415/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -3024.5659 - accuracy: 0.6719 - val_loss: -1870.8341 - val_accuracy: 0.5246\n",
      "Epoch 416/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3030.9446 - accuracy: 0.6709 - val_loss: -1869.9086 - val_accuracy: 0.5279\n",
      "Epoch 417/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3042.1516 - accuracy: 0.6732 - val_loss: -1872.9269 - val_accuracy: 0.5285\n",
      "Epoch 418/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -3046.8367 - accuracy: 0.6719 - val_loss: -1880.3414 - val_accuracy: 0.5252\n",
      "Epoch 419/500\n",
      "191/191 [==============================] - 16s 83ms/step - loss: -3056.4316 - accuracy: 0.6719 - val_loss: -1859.8716 - val_accuracy: 0.5305\n",
      "Epoch 420/500\n",
      "191/191 [==============================] - 16s 82ms/step - loss: -3063.8464 - accuracy: 0.6726 - val_loss: -1867.9019 - val_accuracy: 0.5311\n",
      "Epoch 421/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -3060.4438 - accuracy: 0.6716 - val_loss: -1878.3402 - val_accuracy: 0.5331\n",
      "Epoch 422/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -3075.3203 - accuracy: 0.6690 - val_loss: -1876.6344 - val_accuracy: 0.5325\n",
      "Epoch 423/500\n",
      "191/191 [==============================] - 15s 81ms/step - loss: -3087.7273 - accuracy: 0.6727 - val_loss: -1921.3395 - val_accuracy: 0.5344\n",
      "Epoch 424/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -3093.0083 - accuracy: 0.6703 - val_loss: -1902.9167 - val_accuracy: 0.5305\n",
      "Epoch 425/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -3102.0972 - accuracy: 0.6749 - val_loss: -1936.8497 - val_accuracy: 0.5259\n",
      "Epoch 426/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -3106.3491 - accuracy: 0.6732 - val_loss: -1910.8680 - val_accuracy: 0.5351\n",
      "Epoch 427/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3115.5342 - accuracy: 0.6729 - val_loss: -1940.6788 - val_accuracy: 0.5338\n",
      "Epoch 428/500\n",
      "191/191 [==============================] - 17s 88ms/step - loss: -3121.0955 - accuracy: 0.6727 - val_loss: -1959.3169 - val_accuracy: 0.5377\n",
      "Epoch 429/500\n",
      "191/191 [==============================] - 17s 87ms/step - loss: -3130.6233 - accuracy: 0.6740 - val_loss: -1947.6014 - val_accuracy: 0.5272\n",
      "Epoch 430/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3140.8862 - accuracy: 0.6718 - val_loss: -1943.7152 - val_accuracy: 0.5338\n",
      "Epoch 431/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -3142.3767 - accuracy: 0.6704 - val_loss: -1914.7672 - val_accuracy: 0.5370\n",
      "Epoch 432/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3152.5442 - accuracy: 0.6724 - val_loss: -1964.7653 - val_accuracy: 0.5331\n",
      "Epoch 433/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -3158.3196 - accuracy: 0.6749 - val_loss: -1970.3165 - val_accuracy: 0.5338\n",
      "Epoch 434/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -3169.8582 - accuracy: 0.6734 - val_loss: -1988.5831 - val_accuracy: 0.5377\n",
      "Epoch 435/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -3169.8423 - accuracy: 0.6724 - val_loss: -1935.7122 - val_accuracy: 0.5416\n",
      "Epoch 436/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -3179.1829 - accuracy: 0.6713 - val_loss: -1969.9410 - val_accuracy: 0.5390\n",
      "Epoch 437/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3188.5193 - accuracy: 0.6734 - val_loss: -1966.6080 - val_accuracy: 0.5384\n",
      "Epoch 438/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -3198.9736 - accuracy: 0.6745 - val_loss: -1987.3055 - val_accuracy: 0.5344\n",
      "Epoch 439/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3205.4778 - accuracy: 0.6729 - val_loss: -2008.2079 - val_accuracy: 0.5325\n",
      "Epoch 440/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -3209.9846 - accuracy: 0.6724 - val_loss: -1980.7449 - val_accuracy: 0.5423\n",
      "Epoch 441/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -3219.8323 - accuracy: 0.6716 - val_loss: -2021.2720 - val_accuracy: 0.5351\n",
      "Epoch 442/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -3224.9658 - accuracy: 0.6736 - val_loss: -2022.7451 - val_accuracy: 0.5377\n",
      "Epoch 443/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3235.5789 - accuracy: 0.6721 - val_loss: -1989.4708 - val_accuracy: 0.5397\n",
      "Epoch 444/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3239.3308 - accuracy: 0.6727 - val_loss: -1996.9600 - val_accuracy: 0.5384\n",
      "Epoch 445/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3244.4258 - accuracy: 0.6731 - val_loss: -2038.9619 - val_accuracy: 0.5338\n",
      "Epoch 446/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3246.8005 - accuracy: 0.6711 - val_loss: -2003.6315 - val_accuracy: 0.5370\n",
      "Epoch 447/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -3258.9534 - accuracy: 0.6731 - val_loss: -2019.2228 - val_accuracy: 0.5370\n",
      "Epoch 448/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -3266.6091 - accuracy: 0.6716 - val_loss: -2060.7771 - val_accuracy: 0.5377\n",
      "Epoch 449/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3274.5332 - accuracy: 0.6737 - val_loss: -2011.8557 - val_accuracy: 0.5364\n",
      "Epoch 450/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -3281.1680 - accuracy: 0.6713 - val_loss: -2053.6521 - val_accuracy: 0.5364\n",
      "Epoch 451/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3291.3967 - accuracy: 0.6727 - val_loss: -2063.6392 - val_accuracy: 0.5377\n",
      "Epoch 452/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3297.5220 - accuracy: 0.6716 - val_loss: -1942.7953 - val_accuracy: 0.5410\n",
      "Epoch 453/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3298.2068 - accuracy: 0.6706 - val_loss: -1972.3594 - val_accuracy: 0.5384\n",
      "Epoch 454/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -3310.4980 - accuracy: 0.6713 - val_loss: -2047.9775 - val_accuracy: 0.5384\n",
      "Epoch 455/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -3313.2163 - accuracy: 0.6691 - val_loss: -2061.4270 - val_accuracy: 0.5338\n",
      "Epoch 456/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3323.2417 - accuracy: 0.6696 - val_loss: -2052.0332 - val_accuracy: 0.5338\n",
      "Epoch 457/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3334.1929 - accuracy: 0.6739 - val_loss: -2028.8834 - val_accuracy: 0.5357\n",
      "Epoch 458/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3338.4905 - accuracy: 0.6739 - val_loss: -2047.7743 - val_accuracy: 0.5325\n",
      "Epoch 459/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3351.6650 - accuracy: 0.6740 - val_loss: -2061.4653 - val_accuracy: 0.5325\n",
      "Epoch 460/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -3354.6755 - accuracy: 0.6716 - val_loss: -2046.7944 - val_accuracy: 0.5338\n",
      "Epoch 461/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -3355.6299 - accuracy: 0.6706 - val_loss: -2035.6821 - val_accuracy: 0.5305\n",
      "Epoch 462/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -3367.2100 - accuracy: 0.6724 - val_loss: -2098.3689 - val_accuracy: 0.5285\n",
      "Epoch 463/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3377.2395 - accuracy: 0.6698 - val_loss: -2081.9734 - val_accuracy: 0.5338\n",
      "Epoch 464/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3383.2461 - accuracy: 0.6718 - val_loss: -2069.5835 - val_accuracy: 0.5331\n",
      "Epoch 465/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -3388.9524 - accuracy: 0.6683 - val_loss: -2075.4392 - val_accuracy: 0.5357\n",
      "Epoch 466/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3398.2053 - accuracy: 0.6686 - val_loss: -2118.3574 - val_accuracy: 0.5344\n",
      "Epoch 467/500\n",
      "191/191 [==============================] - 14s 76ms/step - loss: -3403.8635 - accuracy: 0.6686 - val_loss: -2101.5176 - val_accuracy: 0.5318\n",
      "Epoch 468/500\n",
      "191/191 [==============================] - 14s 75ms/step - loss: -3408.9277 - accuracy: 0.6693 - val_loss: -2116.0706 - val_accuracy: 0.5318\n",
      "Epoch 469/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3419.1096 - accuracy: 0.6713 - val_loss: -2093.4807 - val_accuracy: 0.5325\n",
      "Epoch 470/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3430.5198 - accuracy: 0.6732 - val_loss: -2132.5188 - val_accuracy: 0.5338\n",
      "Epoch 471/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -3440.5618 - accuracy: 0.6719 - val_loss: -2153.5669 - val_accuracy: 0.5357\n",
      "Epoch 472/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3444.0498 - accuracy: 0.6752 - val_loss: -2092.2939 - val_accuracy: 0.5357\n",
      "Epoch 473/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -3448.0784 - accuracy: 0.6722 - val_loss: -2092.5083 - val_accuracy: 0.5364\n",
      "Epoch 474/500\n",
      "191/191 [==============================] - 14s 75ms/step - loss: -3440.7625 - accuracy: 0.6681 - val_loss: -2095.2432 - val_accuracy: 0.5357\n",
      "Epoch 475/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -3453.8101 - accuracy: 0.6716 - val_loss: -2139.0391 - val_accuracy: 0.5364\n",
      "Epoch 476/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -3468.9990 - accuracy: 0.6706 - val_loss: -2180.0088 - val_accuracy: 0.5338\n",
      "Epoch 477/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3478.8613 - accuracy: 0.6718 - val_loss: -2131.4697 - val_accuracy: 0.5338\n",
      "Epoch 478/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3484.8933 - accuracy: 0.6716 - val_loss: -2161.0366 - val_accuracy: 0.5357\n",
      "Epoch 479/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3492.4553 - accuracy: 0.6688 - val_loss: -2147.7617 - val_accuracy: 0.5357\n",
      "Epoch 480/500\n",
      "191/191 [==============================] - 14s 76ms/step - loss: -3500.2068 - accuracy: 0.6713 - val_loss: -2166.0725 - val_accuracy: 0.5377\n",
      "Epoch 481/500\n",
      "191/191 [==============================] - 14s 76ms/step - loss: -3508.5933 - accuracy: 0.6740 - val_loss: -2183.9998 - val_accuracy: 0.5370\n",
      "Epoch 482/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -3517.5095 - accuracy: 0.6734 - val_loss: -2169.3267 - val_accuracy: 0.5357\n",
      "Epoch 483/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -3514.0579 - accuracy: 0.6695 - val_loss: -2094.6814 - val_accuracy: 0.5252\n",
      "Epoch 484/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3519.4875 - accuracy: 0.6680 - val_loss: -2163.5503 - val_accuracy: 0.5325\n",
      "Epoch 485/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3530.8044 - accuracy: 0.6706 - val_loss: -2194.9128 - val_accuracy: 0.5357\n",
      "Epoch 486/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -3538.5757 - accuracy: 0.6690 - val_loss: -2196.8132 - val_accuracy: 0.5344\n",
      "Epoch 487/500\n",
      "191/191 [==============================] - 14s 75ms/step - loss: -3551.6482 - accuracy: 0.6703 - val_loss: -2228.5388 - val_accuracy: 0.5338\n",
      "Epoch 488/500\n",
      "191/191 [==============================] - 15s 76ms/step - loss: -3563.0022 - accuracy: 0.6714 - val_loss: -2216.1689 - val_accuracy: 0.5370\n",
      "Epoch 489/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -3569.5754 - accuracy: 0.6714 - val_loss: -2214.6572 - val_accuracy: 0.5338\n",
      "Epoch 490/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3572.9341 - accuracy: 0.6714 - val_loss: -2219.5845 - val_accuracy: 0.5344\n",
      "Epoch 491/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -3584.0908 - accuracy: 0.6732 - val_loss: -2216.7502 - val_accuracy: 0.5370\n",
      "Epoch 492/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -3588.9351 - accuracy: 0.6732 - val_loss: -2224.8333 - val_accuracy: 0.5338\n",
      "Epoch 493/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -3595.1575 - accuracy: 0.6704 - val_loss: -2210.5500 - val_accuracy: 0.5344\n",
      "Epoch 494/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -3603.9363 - accuracy: 0.6732 - val_loss: -2198.9854 - val_accuracy: 0.5384\n",
      "Epoch 495/500\n",
      "191/191 [==============================] - 15s 77ms/step - loss: -3610.7393 - accuracy: 0.6719 - val_loss: -2197.5708 - val_accuracy: 0.5370\n",
      "Epoch 496/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -3619.4778 - accuracy: 0.6718 - val_loss: -2196.3711 - val_accuracy: 0.5338\n",
      "Epoch 497/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3623.4563 - accuracy: 0.6724 - val_loss: -2229.0361 - val_accuracy: 0.5331\n",
      "Epoch 498/500\n",
      "191/191 [==============================] - 15s 79ms/step - loss: -3635.6555 - accuracy: 0.6704 - val_loss: -2245.6575 - val_accuracy: 0.5364\n",
      "Epoch 499/500\n",
      "191/191 [==============================] - 15s 80ms/step - loss: -3644.6792 - accuracy: 0.6734 - val_loss: -2227.7483 - val_accuracy: 0.5390\n",
      "Epoch 500/500\n",
      "191/191 [==============================] - 15s 78ms/step - loss: -3646.7764 - accuracy: 0.6729 - val_loss: -2233.4827 - val_accuracy: 0.5364\n",
      "Accuracy: 53.63934636116028 %\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Word2Vec' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 56\u001B[0m\n\u001B[0;32m     53\u001B[0m scores \u001B[38;5;241m=\u001B[39m model_lstm\u001B[38;5;241m.\u001B[39mevaluate(test_X, test_y, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mscores[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m100\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m %\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 56\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_classes\u001B[49m(test_X)\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuracy:\u001B[39m\u001B[38;5;124m\"\u001B[39m, accuracy_score(test_y, y_pred))\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConfusion Matrix:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, confusion_matrix(test_y, y_pred))\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Word2Vec' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.utils import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import LSTM\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import gensim.models.keyedvectors as w2vmodel\n",
    "\n",
    "\n",
    "data_label = pd.read_csv(\"dataset_final_vader.csv\", delimiter=';')\n",
    "data_tweet_fix = pd.read_csv(\"fix_with_slang.csv\", delimiter=';')\n",
    "data_label['text_id'] = data_tweet_fix['text_id']\n",
    "data_label.drop([\"origin_text_id\", \"origin_text_en\",\"text_en\"], axis=1)\n",
    "\n",
    "# data_label = data_label.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "w2v_model = Word2Vec.load(\"model/w2v/etle_dataset_origin_text.model\")\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data_label['text_id'])\n",
    "X = tokenizer.texts_to_sequences(data_label['text_id'])\n",
    "\n",
    "max_len_tweet = 60\n",
    "X = pad_sequences(X, maxlen=max_len_tweet)\n",
    "print(X.shape)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_matrix = np.zeros((vocab_size, 128))\n",
    "for word,i in tokenizer.word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(vocab_size,128, weights=[embedding_matrix], input_length=max_len_tweet))\n",
    "model_lstm.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model_lstm.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "model_lstm.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "train_size = int(len(data_label) * 0.8)\n",
    "train_X, test_X = X[:train_size], X[train_size:]\n",
    "train_y, test_y = data_label[\"label_vader\"][:train_size], data_label[\"label_vader\"][train_size:]\n",
    "\n",
    "train_X = np.stack(train_X, axis=0)\n",
    "train_y = np.stack(train_y, axis=0)\n",
    "model_lstm.fit(train_X, train_y, validation_data=(test_X, test_y), epochs=500, batch_size=32)\n",
    "\n",
    "scores = model_lstm.evaluate(test_X, test_y, verbose=0)\n",
    "print(f\"Accuracy: {scores[1]*100} %\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 1s 10ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m model_lstm\u001B[38;5;241m.\u001B[39mpredict(test_X)\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuracy:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[43maccuracy_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConfusion Matrix:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, confusion_matrix(test_y, y_pred))\n",
      "File \u001B[1;32m~\\PycharmProjects\\skripsi_bert_ngab\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:192\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    187\u001B[0m validate_parameter_constraints(\n\u001B[0;32m    188\u001B[0m     parameter_constraints, params, caller_name\u001B[38;5;241m=\u001B[39mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\n\u001B[0;32m    189\u001B[0m )\n\u001B[0;32m    191\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 192\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    193\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    194\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    195\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    196\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    197\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    198\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    199\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    200\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    201\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    202\u001B[0m     )\n",
      "File \u001B[1;32m~\\PycharmProjects\\skripsi_bert_ngab\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:221\u001B[0m, in \u001B[0;36maccuracy_score\u001B[1;34m(y_true, y_pred, normalize, sample_weight)\u001B[0m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Accuracy classification score.\u001B[39;00m\n\u001B[0;32m    156\u001B[0m \n\u001B[0;32m    157\u001B[0m \u001B[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    217\u001B[0m \u001B[38;5;124;03m0.5\u001B[39;00m\n\u001B[0;32m    218\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    220\u001B[0m \u001B[38;5;66;03m# Compute accuracy for each possible representation\u001B[39;00m\n\u001B[1;32m--> 221\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m \u001B[43m_check_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    222\u001B[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultilabel\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[1;32m~\\PycharmProjects\\skripsi_bert_ngab\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:95\u001B[0m, in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     92\u001B[0m     y_type \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(y_type) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 95\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m     96\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClassification metrics can\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt handle a mix of \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m targets\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m     97\u001B[0m             type_true, type_pred\n\u001B[0;32m     98\u001B[0m         )\n\u001B[0;32m     99\u001B[0m     )\n\u001B[0;32m    101\u001B[0m \u001B[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001B[39;00m\n\u001B[0;32m    102\u001B[0m y_type \u001B[38;5;241m=\u001B[39m y_type\u001B[38;5;241m.\u001B[39mpop()\n",
      "\u001B[1;31mValueError\u001B[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "y_pred = model_lstm.predict(test_X)\n",
    "print(\"Accuracy:\", accuracy_score(test_y, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(test_y, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_lstm_53.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_lstm_53.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model_lstm.save('model_lstm_53.model')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model_lstm.to_json()\n",
    "with open(\"model_lstm_53.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_lstm.save_weights(\"model_lstm_53.h5\")\n",
    "print(\"Saved model to disk\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
