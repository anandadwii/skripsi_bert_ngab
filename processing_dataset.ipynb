{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "import textblob.exceptions\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from deep_translator import GoogleTranslator\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import csv\n",
    "import time\n",
    "import tensorflow as tf\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_enter(val):\n",
    "    \"\"\"menghilangkan \\n atau enter\"\"\"\n",
    "    return ' '.join(val.split())\n",
    "\n",
    "def remove_emoji():\n",
    "    \"\"\"menghilangkan emoji\"\"\"\n",
    "    emojis = sorted(emoji.EMOJI_DATA, key=len, reverse=True)\n",
    "    pattern = u'(' + u'|'.join(re.escape(u) for u in emojis) + u')'\n",
    "    return re.compile(pattern)\n",
    "\n",
    "begone_emoji = remove_emoji()\n",
    "\n",
    "def remove_three_same_char(value):\n",
    "    \"\"\"menghilangkan repitisi 3 karakter berurutan seperti gooooool\"\"\"\n",
    "    pattern = re.compile(r\"(.)\\1{1,}\", re.DOTALL)\n",
    "    return pattern.sub(r\"\\1\\1\", value)\n",
    "\n",
    "def preprocessing_data(val):\n",
    "    \"\"\"\n",
    "    lower huruf, menghilangkan hyperlink, unicode, RT, menghilangkan titik koma ganda,\n",
    "    menghilangkan enter dan emoji.\n",
    "    \"\"\"\n",
    "    result = val.lower().strip()\n",
    "    result = remove_enter(result)\n",
    "    result = re.sub(r'(@|https?)\\S+|#[A-Za-z0-9_]+', '', result).replace(\"&amp;\", \"dan\")\n",
    "    result = re.sub(r'RT[\\s]+','',result)\n",
    "    result = re.sub('[^.,a-zA-Z0-9 \\n\\.]', '', result)\n",
    "    # result = re.sub(r'\\d', '', result)\n",
    "    # result = re.sub(r'[^\\w\\s]', ' ', result)\n",
    "    result = re.sub(r'\\.+', \" . \", result)\n",
    "    result = re.sub(r'\\,+', \" , \", result)\n",
    "    result = remove_three_same_char(result)\n",
    "    result = begone_emoji.sub(repl='', string=result)\n",
    "    return result\n",
    "\n",
    "def final_remove(val):\n",
    "    \"\"\"\n",
    "   fungsi ini digunakan untuk melakukan preprocessing akhir yaitu menghilangkan titk, koma dan karakter selain alfabet.\n",
    "   setelah bersih akan dilakukan remove stopword dan stemming\n",
    "    \"\"\"\n",
    "    result = re.sub(r'[^\\w\\s]', ' ', val)\n",
    "    result = re.sub(r'\\d', '', result)\n",
    "    result = convertSlangWord(result)\n",
    "    result = remove_stopword_stemming(result)\n",
    "    return result\n",
    "\n",
    "factory = StopWordRemoverFactory()\n",
    "stopwords_id = factory.get_stop_words()\n",
    "stopword_id = factory.create_stop_word_remover()\n",
    "stemmer = StemmerFactory().create_stemmer()\n",
    "\n",
    "def remove_stopword_stemming(val):\n",
    "    \"\"\"menghilangkan stopword dan mengubah kata menjadi kata dasar bahasa indonesia\"\"\"\n",
    "    removed = stopword_id.remove(val)\n",
    "    removed = stemmer.stem(removed)\n",
    "    return removed\n",
    "\n",
    "def polarity_decider(val):\n",
    "    \"\"\"melihat polaritas menggunakan TextBlob\"\"\"\n",
    "    analize = TextBlob(val)\n",
    "    processed = analize.sentiment\n",
    "    if processed.polarity > 0:\n",
    "        sentimen = 1\n",
    "    elif processed.polarity < 0:\n",
    "        sentimen = -1\n",
    "    else:\n",
    "        sentimen = 0\n",
    "    return sentimen\n",
    "\n",
    "eng_stemmer = PorterStemmer()\n",
    "def eng_final_remove(val):\n",
    "    \"\"\"melakukan preprocessing akhir pada teks english yaitu menghilangkan karakter non alfabet,\n",
    "    remove stopword, dan stemming\"\"\"\n",
    "    remove_non_char = re.sub(r'[^\\w\\s]', ' ', val.lower())\n",
    "    result = re.sub(r'\\d', '', remove_non_char)\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    tokens = word_tokenize(result)\n",
    "    remove_sw = [word for word in tokens if not word in stopwords_english]\n",
    "    stemming_en = [eng_stemmer.stem(word) for word in remove_sw]\n",
    "    return  ' '.join(stemming_en)\n",
    "\n",
    "def translate(value, src = 'id', target = 'en'):\n",
    "    \"\"\" menerjemahkan bahasa indonesia ke inggris secara default\"\"\"\n",
    "    result = GoogleTranslator(source=src, target=target).translate(value)\n",
    "    return result\n",
    "\n",
    "def vader_sentiment(sentence):\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "    if sentiment_dict['compound'] >= 0.05 :\n",
    "        value = 1\n",
    "    elif sentiment_dict['compound'] <= - 0.05 :\n",
    "        value = -1\n",
    "    else :\n",
    "        value = 0\n",
    "    return value\n",
    "\n",
    "def convertSlangWord(value):\n",
    "    kamus = eval(open(\"combined_slang_words.txt\").read())\n",
    "    pattern = re.compile(r\"\\b(%s)\\b\" % \"|\".join(kamus))\n",
    "    converted = pattern.sub(lambda word: kamus.get(word.group()), value)\n",
    "    # clear = re.sub(r'[^\\w\\s]', ' ', converted)\n",
    "    return converted"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "text = df[0][0]\n",
    "cleaned = preprocessing_data(text)\n",
    "test = detect(cleaned)\n",
    "print(test)\n",
    "print(cleaned)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def cleaning(open_file_dir: str, save_file_dir: str):\n",
    "    error_bucket = []\n",
    "    start = time.time()\n",
    "    with open(open_file_dir) as csv_data:\n",
    "        load_data = list(csv.reader(csv_data, delimiter=';'))\n",
    "        dictionary = {}\n",
    "        list_of_dictionary = []\n",
    "        for index,item in enumerate(load_data[1:]):\n",
    "            # print((start_row+index))\n",
    "            # print(item[0])\n",
    "            # break\n",
    "            if index%500 == 0:\n",
    "                # prevent API limitation around 550-800 at batch request\n",
    "                time.sleep(20)\n",
    "            try:\n",
    "                translate_en = translate(preprocessing_data(item[0]))\n",
    "                origin_id = preprocessing_data(item[0])\n",
    "                # sentiment, translated = polarity_decider(preprocessing_data(item[0]))\n",
    "                dictionary = {\n",
    "                    'origin_text_id' : origin_id,\n",
    "                    'text_id': final_remove(origin_id),\n",
    "                    'origin_text_en': translate_en,\n",
    "                    # 'text_en': eng_final_remove(preprocessing_data(translated)),\n",
    "                    'text_en': eng_final_remove(translate_en),\n",
    "                    'label_vader' : vader_sentiment(translate_en),\n",
    "                    # 'label_textblob':sentiment\n",
    "                }\n",
    "                list_of_dictionary.append(dictionary)\n",
    "            except:\n",
    "                # error_bucket.append(index)\n",
    "                continue\n",
    "    # print(len(list_of_dictionary))\n",
    "    end = time.time()\n",
    "    delta = end - start\n",
    "    # print(f\"time execute : {delta} seconds\")\n",
    "    df_clean = pd.DataFrame(list_of_dictionary)\n",
    "    df_clean.to_csv(save_file_dir, index=False, sep=';')\n",
    "    return_message ={\n",
    "        \"time execute\": f\"{delta} seconds\",\n",
    "        \"saved file\" : save_file_dir\n",
    "    }\n",
    "    return return_message"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "cores = cpu_count()-1\n",
    "results = []\n",
    "with open('data oktober-des 2022 etilang tanpa lang dan etle.csv', encoding='utf-8') as csv_data:\n",
    "    load_data = list(csv.reader(csv_data, delimiter=';'))\n",
    "    load_data.pop(0)\n",
    "    chunks = np.array_split(load_data, cores)\n",
    "\n",
    "\n",
    "def worker(raw: list) -> list:\n",
    "    processed_bucket = []\n",
    "    for data in raw:\n",
    "        temp_dict = {\n",
    "            'text_id': final_remove(preprocessing_data(str(data)))\n",
    "        }\n",
    "        processed_bucket.append(temp_dict)\n",
    "\n",
    "    return processed_bucket\n",
    "start = time.time()\n",
    "with ThreadPoolExecutor(cores) as executor:\n",
    "    for result in executor.map(worker, chunks):\n",
    "        results.extend(result)\n",
    "end = time.time()\n",
    "delta = end-start\n",
    "print(f\"time execute with multithreading : {delta} seconds\")\n",
    "df_clean = pd.DataFrame(results)\n",
    "df_clean.to_csv('fix_with_slang_multithreading.csv', index=False, sep=';')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "error_bucket = []\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open('dataset_final_vader.csv', encoding='utf-8') as csv_data:\n",
    "    load_data = list(csv.reader(csv_data, delimiter=';'))\n",
    "    dictionary = {}\n",
    "    list_of_dictionary = []\n",
    "    start_row = 1\n",
    "    for index,item in enumerate(load_data[start_row:]):\n",
    "        # print((start_row+index))\n",
    "        # if index%500 == 0:\n",
    "        #     time.sleep(30)\n",
    "        # print(item[0])\n",
    "        # break\n",
    "        try:\n",
    "            # translate_en = translate(preprocessing_data(item[0]))\n",
    "            origin_id = preprocessing_data(item[0])\n",
    "            # sentiment, translated = polarity_decider(preprocessing_data(item[0]))\n",
    "            dictionary = {\n",
    "                # 'origin_text_id' : origin_id,\n",
    "                'text_id': final_remove(origin_id)\n",
    "                # 'origin_text_en': translate_en,\n",
    "                # 'text_en': eng_final_remove(preprocessing_data(translated)),\n",
    "                # 'text_en': eng_final_remove(translate_en),\n",
    "                # 'label_vader' : vader_sentiment(translate_en),\n",
    "                # 'label_textblob':sentiment\n",
    "            }\n",
    "            list_of_dictionary.append(dictionary)\n",
    "        except:\n",
    "            error_bucket.append(index)\n",
    "# print(len(list_of_dictionary))\n",
    "end = time.time()\n",
    "delta = end- start\n",
    "print(f\"time execute : {delta} seconds\")\n",
    "\n",
    "df_clean = pd.DataFrame(list_of_dictionary)\n",
    "df_clean.to_csv('fix_with_slang.csv', index=False, sep=';')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_of_dictionary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('dataset_final_vader.csv') as csv_data:\n",
    "    load_data = list(csv.reader(csv_data, delimiter=';'))\n",
    "    dictionary = {}\n",
    "    list_of_dictionary = []\n",
    "    for index,item in enumerate(load_data[1:]):\n",
    "        try:\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_try = pd.read_csv('dataset_final_vader.csv', sep=';')\n",
    "df_try.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_try['label_textblob'] = df_try['origin_text_en'].apply(lambda x: polarity_decider(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_try.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = df_try['label_textblob']\n",
    "labels_count = labels.value_counts()\n",
    "labels_count.plot(kind='bar')\n",
    "print(labels_count.value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_try.to_csv('dataset_vader_textblob.csv',index=False, sep=';')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}