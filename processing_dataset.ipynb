{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import re\n",
    "from typing import Any\n",
    "from textblob import TextBlob\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "import textblob.exceptions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                             text_id\n0  Kembangkan ETLE, 7 Polda Dapat Penghargaan di ...\n1  Sosialisasi etle dan app smart city\\n\\n#polsek...\n2  Berita populer kumparanOTO, Selasa (13/12) det...\n3  Mimin kasih info ya gaes, kita mau uji coba ET...\n4  personil lalu lintas polres badung melaksanaka...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Kembangkan ETLE, 7 Polda Dapat Penghargaan di ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sosialisasi etle dan app smart city\\n\\n#polsek...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Berita populer kumparanOTO, Selasa (13/12) det...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Mimin kasih info ya gaes, kita mau uji coba ET...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>personil lalu lintas polres badung melaksanaka...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = pd.read_excel('data oktober-des 2022 etilang tanpa lang dan etle.xlsx')\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def remove_enter(val):\n",
    "    return ' '.join(val.split())\n",
    "\n",
    "def remove_emoji():\n",
    "    emojis = sorted(emoji.EMOJI_DATA, key=len, reverse=True)\n",
    "    pattern = u'(' + u'|'.join(re.escape(u) for u in emojis) + u')'\n",
    "    return re.compile(pattern)\n",
    "\n",
    "begone_emoji = remove_emoji()\n",
    "\n",
    "def preprocessing_data(val):\n",
    "    result = val.lower().strip()\n",
    "    result = re.sub(r'(@|https?)\\S+|#[A-Za-z0-9_]+', '', result).replace(\"&amp;\", \"dan\")\n",
    "    result = re.sub(r'RT[\\s]+','',result)\n",
    "    result = re.sub('[^.,a-zA-Z0-9 \\n\\.]', '', result)\n",
    "    result = re.sub(r'\\d', '', result)\n",
    "    # result = re.sub(r'[^\\w\\s]', ' ', result)\n",
    "    result = re.sub(r'\\.+', \" . \", result)\n",
    "    result = re.sub(r'\\,+', \" , \", result)\n",
    "    result = remove_enter(result)\n",
    "    result = begone_emoji.sub(repl='', string=result)\n",
    "    return result\n",
    "\n",
    "def final_remove(val):\n",
    "    result = re.sub(r'\\.+', \" . \", val)\n",
    "    result = re.sub(r'\\,+', \" , \", result)\n",
    "    result = remove_stopword(result)\n",
    "    result = stemming(result)\n",
    "    return result\n",
    "\n",
    "factory = StopWordRemoverFactory()\n",
    "stopwords = factory.get_stop_words()\n",
    "stopword = factory.create_stop_word_remover()\n",
    "stemmer = StemmerFactory().create_stemmer()\n",
    "def remove_stopword(val):\n",
    "    removed = stopword.remove(val)\n",
    "    return removed\n",
    "\n",
    "def stemming(val):\n",
    "    hasil = stemmer.stem(val)\n",
    "    return hasil\n",
    "\n",
    "def polarity_decider(val):\n",
    "    analize = TextBlob(val)\n",
    "    processed = analize.translate(from_lang='id', to='en')\n",
    "    if processed.polarity > 0:\n",
    "        sentimen = 1\n",
    "    elif processed.polarity < 0:\n",
    "        sentimen = -1\n",
    "    else:\n",
    "        sentimen = 0\n",
    "    return sentimen, str(processed).lower()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "'kembangkan etle , polda dapat penghargaan di rakernis fungsi gakkum'"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = preprocessing_data(\"kembangkan etle, polda dapat penghargaan di rakernis fungsi gakkum\")\n",
    "test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "kembangkan etle , polda dapat penghargaan di rakernis fungsi gakkum\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "text = df[0][0]\n",
    "cleaned = preprocessing_data(text)\n",
    "test = detect(cleaned)\n",
    "print(test)\n",
    "print(cleaned)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "with open('data oktober-des 2022 etilang tanpa lang dan etle.csv', encoding='utf-8') as csv_data:\n",
    "    load_data = list(csv.reader(csv_data, delimiter=';'))\n",
    "    dictionary = {}\n",
    "    list_of_dictionary = []\n",
    "\n",
    "    for item in load_data[1:5]:\n",
    "        # print(item[0])\n",
    "        # break\n",
    "        try:\n",
    "            sentiment, translated = polarity_decider(preprocessing_data(item[0]))\n",
    "            dictionary = {\n",
    "                'origin_text' : item[0],\n",
    "                'text_id': final_remove(preprocessing_data(item[0])),\n",
    "                'text_en': translated,\n",
    "                'label' : sentiment\n",
    "            }\n",
    "            list_of_dictionary.append(dictionary)\n",
    "        except textblob.exceptions.NotTranslated:\n",
    "            pass\n",
    "len(list_of_dictionary)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'origin_text': 'Kembangkan ETLE, 7 Polda Dapat Penghargaan di Rakernis Fungsi Gakkum https://t.co/FmqJ5SAFLE',\n  'text_id': 'kembang etle polda harga rakernis fungsi gakkum',\n  'text_en': 'develop ethle, polda can be awarded at the rakernis function gakkum',\n  'label': 0},\n {'origin_text': 'Sosialisasi etle dan app smart city\\n\\n#polsekrambangtengah https://t.co/d8BUmEZZJ5',\n  'text_id': 'sosialisasi etle app smart city',\n  'text_en': 'etle socialization and app smart city',\n  'label': 1},\n {'origin_text': 'Berita populer kumparanOTO, Selasa (13/12) detail Vespa Batik seharga Rp 77 juta, cara kerja dan jenis pelanggaran tilang ETLE mobile. #kumparanOTO https://t.co/YtXCinS9NK',\n  'text_id': 'berita populer kumparanoto selasa detail vespa batik harga rp juta cara kerja jenis langgar tilang etle mobile',\n  'text_en': 'popular news kumparanoto, tuesday vespa batik details for rp',\n  'label': 1},\n {'origin_text': 'Mimin kasih info ya gaes, kita mau uji coba ETLE di wilayah Tangerang Kota nih..\\n\\nYukss patuhi peraturan Lalu Lintas, biar ngga dapet surat cinta dari mimin ðŸ¤­ https://t.co/rV1oW4Z3Xo',\n  'text_id': 'mimin kasih info gaes mau uji coba etle wilayah tangerang kota nih yukss patuh atur lalu lintas biar ngga dapet surat cinta mimin',\n  'text_en': \"mimin give me info, we want to test etle in the tangerang city area. yukss obey traffic rules, so you don't get a love letter from mimin\",\n  'label': 1}]"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_dictionary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             text_id  \\\n0    kembang etle polda harga rakernis fungsi gakkum   \n1                    sosialisasi etle app smart city   \n2  berita populer kumparanoto selasa detail vespa...   \n3  mimin kasih info gaes mau uji coba etle wilaya...   \n4  personil lalu lintas polres badung laksana teg...   \n\n                                             text_en  label  \n0  kembang etle polda price rakernis gakkum function      0  \n1                  etle app smart city socialization      1  \n2  popular news kumparanoto tuesday vespa batik d...      1  \n3  mimin gives info gaes want to test the ethle o...      1  \n4  badung police traffic personnel like the human...      0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>text_en</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>kembang etle polda harga rakernis fungsi gakkum</td>\n      <td>kembang etle polda price rakernis gakkum function</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sosialisasi etle app smart city</td>\n      <td>etle app smart city socialization</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>berita populer kumparanoto selasa detail vespa...</td>\n      <td>popular news kumparanoto tuesday vespa batik d...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mimin kasih info gaes mau uji coba etle wilaya...</td>\n      <td>mimin gives info gaes want to test the ethle o...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>personil lalu lintas polres badung laksana teg...</td>\n      <td>badung police traffic personnel like the human...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = pd.DataFrame(list_of_dictionary)\n",
    "df_clean.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "df_clean.to_csv('clear_dataset_stemming_stopword.csv', index=False, sep=';')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "fields_names = ['text_id', 'text_en','label']\n",
    "with open('clear_dataset_3.csv', 'w', encoding='utf-8') as csvfile:\n",
    "    write = csv.DictWriter(csvfile, fieldnames= fields_names)\n",
    "    write.writeheader()\n",
    "    write.writerows(list_of_dictionary)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 3 fields in line 313, saw 4\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mParserError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df_dataset_1 \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mclear_dataset.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# df_dataset_2 = pd.read_csv('clear_dataset_2.csv')\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# df_dataset_3 = pd.read_csv('clear_dataset_3_fix.csv')\u001B[39;00m\n\u001B[0;32m      4\u001B[0m df_dataset_1\u001B[38;5;241m.\u001B[39mhead()\n",
      "File \u001B[1;32m~\\PycharmProjects\\skripsi_bert_ngab\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    210\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[1;32m--> 211\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\skripsi_bert_ngab\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[0;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[0;32m    330\u001B[0m     )\n\u001B[1;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\skripsi_bert_ngab\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    936\u001B[0m     dialect,\n\u001B[0;32m    937\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    946\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[0;32m    947\u001B[0m )\n\u001B[0;32m    948\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 950\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\skripsi_bert_ngab\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    608\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[0;32m    610\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[1;32m--> 611\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\skripsi_bert_ngab\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1778\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m   1771\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[0;32m   1772\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1773\u001B[0m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[0;32m   1774\u001B[0m     (\n\u001B[0;32m   1775\u001B[0m         index,\n\u001B[0;32m   1776\u001B[0m         columns,\n\u001B[0;32m   1777\u001B[0m         col_dict,\n\u001B[1;32m-> 1778\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[attr-defined]\u001B[39;49;00m\n\u001B[0;32m   1779\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\n\u001B[0;32m   1780\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1781\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1782\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\PycharmProjects\\skripsi_bert_ngab\\venv\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:230\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m    228\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    229\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlow_memory:\n\u001B[1;32m--> 230\u001B[0m         chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_low_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    231\u001B[0m         \u001B[38;5;66;03m# destructive to chunks\u001B[39;00m\n\u001B[0;32m    232\u001B[0m         data \u001B[38;5;241m=\u001B[39m _concatenate_chunks(chunks)\n",
      "File \u001B[1;32m~\\PycharmProjects\\skripsi_bert_ngab\\venv\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:808\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\PycharmProjects\\skripsi_bert_ngab\\venv\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:866\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\PycharmProjects\\skripsi_bert_ngab\\venv\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:852\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\PycharmProjects\\skripsi_bert_ngab\\venv\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1973\u001B[0m, in \u001B[0;36mpandas._libs.parsers.raise_parser_error\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mParserError\u001B[0m: Error tokenizing data. C error: Expected 3 fields in line 313, saw 4\n"
     ]
    }
   ],
   "source": [
    "df_dataset_1 = pd.read_csv('clear_dataset.csv')\n",
    "# df_dataset_2 = pd.read_csv('clear_dataset_2.csv')\n",
    "# df_dataset_3 = pd.read_csv('clear_dataset_3_fix.csv')\n",
    "df_dataset_1.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
