{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "import textblob.exceptions\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from deep_translator import GoogleTranslator\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import csv\n",
    "import time\n",
    "import tensorflow as tf\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def remove_enter(val):\n",
    "    \"\"\"menghilangkan \\n atau enter\"\"\"\n",
    "    return ' '.join(val.split())\n",
    "\n",
    "def remove_emoji():\n",
    "    \"\"\"menghilangkan emoji\"\"\"\n",
    "    emojis = sorted(emoji.EMOJI_DATA, key=len, reverse=True)\n",
    "    pattern = u'(' + u'|'.join(re.escape(u) for u in emojis) + u')'\n",
    "    return re.compile(pattern)\n",
    "\n",
    "begone_emoji = remove_emoji()\n",
    "\n",
    "def remove_three_same_char(value):\n",
    "    \"\"\"menghilangkan repitisi 3 karakter berurutan seperti gooooool\"\"\"\n",
    "    pattern = re.compile(r\"(.)\\1{1,}\", re.DOTALL)\n",
    "    return pattern.sub(r\"\\1\\1\", value)\n",
    "\n",
    "def preprocessing_data(val):\n",
    "    \"\"\"\n",
    "    lower huruf, menghilangkan hyperlink, unicode, RT, menghilangkan titik koma ganda,\n",
    "    menghilangkan enter dan emoji.\n",
    "    \"\"\"\n",
    "    result = val.lower().strip()\n",
    "    result = remove_enter(result)\n",
    "    result = re.sub(r'(@|https?)\\S+|#[A-Za-z0-9_]+', '', result).replace(\"&amp;\", \"dan\")\n",
    "    result = re.sub(r'RT[\\s]+','',result)\n",
    "    result = re.sub('[^.,a-zA-Z0-9 \\n\\.]', '', result)\n",
    "    # result = re.sub(r'\\d', '', result)\n",
    "    # result = re.sub(r'[^\\w\\s]', ' ', result)\n",
    "    result = re.sub(r'\\.+', \" . \", result)\n",
    "    result = re.sub(r'\\,+', \" , \", result)\n",
    "    result = remove_three_same_char(result)\n",
    "    result = begone_emoji.sub(repl='', string=result)\n",
    "    return result\n",
    "\n",
    "def final_remove(val):\n",
    "    \"\"\"\n",
    "   fungsi ini digunakan untuk melakukan preprocessing akhir yaitu menghilangkan titk, koma dan karakter selain alfabet.\n",
    "   setelah bersih akan dilakukan remove stopword dan stemming\n",
    "    \"\"\"\n",
    "    result = re.sub(r'[^\\w\\s]', ' ', val)\n",
    "    result = re.sub(r'\\d', '', result)\n",
    "    result = convertSlangWord(result)\n",
    "    result = remove_stopword_stemming(result)\n",
    "    return result\n",
    "\n",
    "factory = StopWordRemoverFactory()\n",
    "stopwords_id = factory.get_stop_words()\n",
    "stopword_id = factory.create_stop_word_remover()\n",
    "stemmer = StemmerFactory().create_stemmer()\n",
    "\n",
    "def remove_stopword_stemming(val):\n",
    "    \"\"\"menghilangkan stopword dan mengubah kata menjadi kata dasar bahasa indonesia\"\"\"\n",
    "    removed = stopword_id.remove(val)\n",
    "    removed = stemmer.stem(removed)\n",
    "    return removed\n",
    "\n",
    "def polarity_decider(val):\n",
    "    \"\"\"melihat polaritas menggunakan TextBlob\"\"\"\n",
    "    analize = TextBlob(val)\n",
    "    processed = analize.translate(from_lang='id', to='en')\n",
    "    if processed.polarity > 0:\n",
    "        sentimen = 1\n",
    "    elif processed.polarity < 0:\n",
    "        sentimen = -1\n",
    "    else:\n",
    "        sentimen = 0\n",
    "    return sentimen, str(processed).lower()\n",
    "\n",
    "eng_stemmer = PorterStemmer()\n",
    "def eng_final_remove(val):\n",
    "    \"\"\"melakukan preprocessing akhir pada teks english yaitu menghilangkan karakter non alfabet,\n",
    "    remove stopword, dan stemming\"\"\"\n",
    "    remove_non_char = re.sub(r'[^\\w\\s]', ' ', val.lower())\n",
    "    result = re.sub(r'\\d', '', remove_non_char)\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    tokens = word_tokenize(result)\n",
    "    remove_sw = [word for word in tokens if not word in stopwords_english]\n",
    "    stemming_en = [eng_stemmer.stem(word) for word in remove_sw]\n",
    "    return  ' '.join(stemming_en)\n",
    "\n",
    "def translate(value, src = 'id', target = 'en'):\n",
    "    \"\"\" menerjemahkan bahasa indonesia ke inggris secara default\"\"\"\n",
    "    result = GoogleTranslator(source=src, target=target).translate(value)\n",
    "    return result\n",
    "\n",
    "def vader_sentiment(sentence):\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "    if sentiment_dict['compound'] >= 0.05 :\n",
    "        value = 1\n",
    "    elif sentiment_dict['compound'] <= - 0.05 :\n",
    "        value = -1\n",
    "    else :\n",
    "        value = 0\n",
    "    return value\n",
    "\n",
    "def convertSlangWord(value):\n",
    "    kamus = eval(open(\"combined_slang_words.txt\").read())\n",
    "    pattern = re.compile(r\"\\b(%s)\\b\" % \"|\".join(kamus))\n",
    "    converted = pattern.sub(lambda word: kamus.get(word.group()), value)\n",
    "    # clear = re.sub(r'[^\\w\\s]', ' ', converted)\n",
    "    return converted"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "'teman goblok'"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test = preprocessing_data(\"kembangkan etle, 7 polda dapat penghargaan di rakernis fungsi gakkum\")\n",
    "# test\n",
    "slang_test = convertSlangWord(\"\")\n",
    "slang_test = remove_stopword_stemming(slang_test)\n",
    "slang_test\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "text = df[0][0]\n",
    "cleaned = preprocessing_data(text)\n",
    "test = detect(cleaned)\n",
    "print(test)\n",
    "print(cleaned)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def cleaning(open_file_dir: str, save_file_dir: str):\n",
    "    error_bucket = []\n",
    "    start = time.time()\n",
    "    with open(open_file_dir) as csv_data:\n",
    "        load_data = list(csv.reader(csv_data, delimiter=';'))\n",
    "        dictionary = {}\n",
    "        list_of_dictionary = []\n",
    "        for index,item in enumerate(load_data[1:]):\n",
    "            # print((start_row+index))\n",
    "            # print(item[0])\n",
    "            # break\n",
    "            if index%500 == 0:\n",
    "                # prevent API limitation around 550-800 at batch request\n",
    "                time.sleep(20)\n",
    "            try:\n",
    "                translate_en = translate(preprocessing_data(item[0]))\n",
    "                origin_id = preprocessing_data(item[0])\n",
    "                # sentiment, translated = polarity_decider(preprocessing_data(item[0]))\n",
    "                dictionary = {\n",
    "                    'origin_text_id' : origin_id,\n",
    "                    'text_id': final_remove(origin_id),\n",
    "                    'origin_text_en': translate_en,\n",
    "                    # 'text_en': eng_final_remove(preprocessing_data(translated)),\n",
    "                    'text_en': eng_final_remove(translate_en),\n",
    "                    'label_vader' : vader_sentiment(translate_en),\n",
    "                    # 'label_textblob':sentiment\n",
    "                }\n",
    "                list_of_dictionary.append(dictionary)\n",
    "            except:\n",
    "                # error_bucket.append(index)\n",
    "                continue\n",
    "    # print(len(list_of_dictionary))\n",
    "    end = time.time()\n",
    "    delta = end - start\n",
    "    # print(f\"time execute : {delta} seconds\")\n",
    "    df_clean = pd.DataFrame(list_of_dictionary)\n",
    "    df_clean.to_csv(save_file_dir, index=False, sep=';')\n",
    "    return_message ={\n",
    "        \"time execute\": f\"{delta} seconds\",\n",
    "        \"saved file\" : save_file_dir\n",
    "    }\n",
    "    return return_message"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time execute with multithreading : 892.9202611446381 seconds\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import cpu_count\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "cores = cpu_count()-1\n",
    "results = []\n",
    "with open('data oktober-des 2022 etilang tanpa lang dan etle.csv', encoding='utf-8') as csv_data:\n",
    "    load_data = list(csv.reader(csv_data, delimiter=';'))\n",
    "    load_data.pop(0)\n",
    "    chunks = np.array_split(load_data, cores)\n",
    "\n",
    "\n",
    "def worker(raw: list) -> list:\n",
    "    processed_bucket = []\n",
    "    for data in raw:\n",
    "        temp_dict = {\n",
    "            'text_id': final_remove(preprocessing_data(str(data)))\n",
    "        }\n",
    "        processed_bucket.append(temp_dict)\n",
    "\n",
    "    return processed_bucket\n",
    "start = time.time()\n",
    "with ThreadPoolExecutor(cores) as executor:\n",
    "    for result in executor.map(worker, chunks):\n",
    "        results.extend(result)\n",
    "end = time.time()\n",
    "delta = end-start\n",
    "print(f\"time execute with multithreading : {delta} seconds\")\n",
    "df_clean = pd.DataFrame(results)\n",
    "df_clean.to_csv('fix_with_slang_multithreading.csv', index=False, sep=';')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time execute : 700.7128784656525 seconds\n"
     ]
    }
   ],
   "source": [
    "error_bucket = []\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open('data oktober-des 2022 etilang tanpa lang dan etle.csv', encoding='utf-8') as csv_data:\n",
    "    load_data = list(csv.reader(csv_data, delimiter=';'))\n",
    "    dictionary = {}\n",
    "    list_of_dictionary = []\n",
    "    start_row = 1\n",
    "    for index,item in enumerate(load_data[start_row:]):\n",
    "        # print((start_row+index))\n",
    "        # if index%500 == 0:\n",
    "        #     time.sleep(30)\n",
    "        # print(item[0])\n",
    "        # break\n",
    "        try:\n",
    "            # translate_en = translate(preprocessing_data(item[0]))\n",
    "            origin_id = preprocessing_data(item[0])\n",
    "            # sentiment, translated = polarity_decider(preprocessing_data(item[0]))\n",
    "            dictionary = {\n",
    "                # 'origin_text_id' : origin_id,\n",
    "                'text_id': final_remove(origin_id)\n",
    "                # 'origin_text_en': translate_en,\n",
    "                # 'text_en': eng_final_remove(preprocessing_data(translated)),\n",
    "                # 'text_en': eng_final_remove(translate_en),\n",
    "                # 'label_vader' : vader_sentiment(translate_en),\n",
    "                # 'label_textblob':sentiment\n",
    "            }\n",
    "            list_of_dictionary.append(dictionary)\n",
    "        except:\n",
    "            error_bucket.append(index)\n",
    "# print(len(list_of_dictionary))\n",
    "end = time.time()\n",
    "delta = end- start\n",
    "print(f\"time execute : {delta} seconds\")\n",
    "\n",
    "df_clean = pd.DataFrame(list_of_dictionary)\n",
    "df_clean.to_csv('fix_with_slang.csv', index=False, sep=';')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'origin_text_id': 'kembangkan etle , 7 polda dapat penghargaan di rakernis fungsi gakkum',\n  'text_id': 'kembang etle polda dapat harga di rakernis fungsi gakkum',\n  'origin_text_en': 'develop etle , 7 regional police won awards at the Gakum function meeting',\n  'text_en': 'develop etl region polic award gakum function meet',\n  'label_vader': 1},\n {'origin_text_id': 'sosialisasi etle dan app smart city',\n  'text_id': 'sosialisasi etle dan app smart city',\n  'origin_text_en': 'etle socialization and smart city app',\n  'text_en': 'etl social smart citi app',\n  'label_vader': 1},\n {'origin_text_id': 'berita populer kumparanoto , selasa 1312 detail vespa batik seharga rp 77 juta , cara kerja dan jenis pelanggaran tilang etle mobile .',\n  'text_id': 'berita populer kumparanoto selasa detail vespa batik harga rp juta cara kerja dan jenis langgar tilang etle mobile',\n  'origin_text_en': 'Kupang Popular News, Tuesday 1312 details Vespa batik worth IDR 77 million, how it works and types of Etle Mobile ticket violations.',\n  'text_en': 'kupang popular news tuesday detail vespa batik worth idr million work type etl mobil ticket violat',\n  'label_vader': 1},\n {'origin_text_id': 'mimin kasih info ya gaes , kita mau uji coba etle di wilayah tangerang kota nih . yukss patuhi peraturan lalu lintas , biar ngga dapet surat cinta dari mimin',\n  'text_id': 'mimin kasih info ya gaes kita mau uji coba etle di wilayah tangerang kota nih yukss patuh atur lalu lintas biar ngga dapet surat cinta dari mimin',\n  'origin_text_en': \"Mimin, give me some info, guys, we want to try out Etle in the Tangerang city area. let's obey the traffic rules, so you don't get a love letter from Mimin\",\n  'text_en': 'mimin give info guy want tri etl tangerang citi area let obey traffic rule get love letter mimin',\n  'label_vader': -1}]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_dictionary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "with open('dataset_final_vader.csv') as csv_data:\n",
    "    load_data = list(csv.reader(csv_data, delimiter=';'))\n",
    "    dictionary = {}\n",
    "    list_of_dictionary = []\n",
    "    for index,item in enumerate(load_data[1:]):\n",
    "        try:\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                      origin_text_id  \\\n0  kembangkan etle , 7 polda dapat penghargaan di...   \n1                sosialisasi etle dan app smart city   \n2  berita populer kumparanoto , selasa 1312 detai...   \n3  mimin kasih info ya gaes , kita mau uji coba e...   \n4  personil lalu lintas polres badung melaksanaka...   \n\n                                             text_id  \\\n0  kembang etle polda dapat harga di rakernis fun...   \n1                sosialisasi etle dan app smart city   \n2  berita populer kumparanoto selasa detail vespa...   \n3  mimin kasih info ya gaes kita mau uji coba etl...   \n4  personil lalu lintas polres badung laksana teg...   \n\n                                      origin_text_en  \\\n0  develop etle , 7 regional police won awards at...   \n1              etle socialization and smart city app   \n2  Kupang Popular News, Tuesday 1312 details Vesp...   \n3  Mimin, give me some info, guys, we want to try...   \n4  Badung Police traffic personnel carry out a hu...   \n\n                                             text_en  label_vader  \n0  develop etl region polic award gakum function ...            1  \n1                          etl social smart citi app            1  \n2  kupang popular news tuesday detail vespa batik...            1  \n3  mimin give info guy want tri etl tangerang cit...           -1  \n4  badung polic traffic personnel carri human war...           -1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>origin_text_id</th>\n      <th>text_id</th>\n      <th>origin_text_en</th>\n      <th>text_en</th>\n      <th>label_vader</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>kembangkan etle , 7 polda dapat penghargaan di...</td>\n      <td>kembang etle polda dapat harga di rakernis fun...</td>\n      <td>develop etle , 7 regional police won awards at...</td>\n      <td>develop etl region polic award gakum function ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sosialisasi etle dan app smart city</td>\n      <td>sosialisasi etle dan app smart city</td>\n      <td>etle socialization and smart city app</td>\n      <td>etl social smart citi app</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>berita populer kumparanoto , selasa 1312 detai...</td>\n      <td>berita populer kumparanoto selasa detail vespa...</td>\n      <td>Kupang Popular News, Tuesday 1312 details Vesp...</td>\n      <td>kupang popular news tuesday detail vespa batik...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mimin kasih info ya gaes , kita mau uji coba e...</td>\n      <td>mimin kasih info ya gaes kita mau uji coba etl...</td>\n      <td>Mimin, give me some info, guys, we want to try...</td>\n      <td>mimin give info guy want tri etl tangerang cit...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>personil lalu lintas polres badung melaksanaka...</td>\n      <td>personil lalu lintas polres badung laksana teg...</td>\n      <td>Badung Police traffic personnel carry out a hu...</td>\n      <td>badung polic traffic personnel carri human war...</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_try = pd.read_csv('dataset_final_vader.csv', sep=';')\n",
    "df_try.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df_try['slang_convert'] = df_try['origin_text_id'].apply(convertSlangWord)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                                      origin_text_id  \\\n0  kembangkan etle , 7 polda dapat penghargaan di...   \n1                sosialisasi etle dan app smart city   \n2  berita populer kumparanoto , selasa 1312 detai...   \n3  mimin kasih info ya gaes , kita mau uji coba e...   \n4  personil lalu lintas polres badung melaksanaka...   \n\n                                             text_id  \\\n0  kembang etle polda dapat harga di rakernis fun...   \n1                sosialisasi etle dan app smart city   \n2  berita populer kumparanoto selasa detail vespa...   \n3  mimin kasih info ya gaes kita mau uji coba etl...   \n4  personil lalu lintas polres badung laksana teg...   \n\n                                      origin_text_en  \\\n0  develop etle , 7 regional police won awards at...   \n1              etle socialization and smart city app   \n2  Kupang Popular News, Tuesday 1312 details Vesp...   \n3  Mimin, give me some info, guys, we want to try...   \n4  Badung Police traffic personnel carry out a hu...   \n\n                                             text_en  label_vader  \\\n0  develop etl region polic award gakum function ...            1   \n1                          etl social smart citi app            1   \n2  kupang popular news tuesday detail vespa batik...            1   \n3  mimin give info guy want tri etl tangerang cit...           -1   \n4  badung polic traffic personnel carri human war...           -1   \n\n                                       slang_convert  \n0  kembangkan etle , 7 polda dapat penghargaan di...  \n1                sosialisasi etle dan app smart city  \n2  berita populer kumparanoto , selasa 1312 detai...  \n3  mimin kasih informasi iya teman-teman , kita m...  \n4  personil lalu lintas polres badung melaksanaka...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>origin_text_id</th>\n      <th>text_id</th>\n      <th>origin_text_en</th>\n      <th>text_en</th>\n      <th>label_vader</th>\n      <th>slang_convert</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>kembangkan etle , 7 polda dapat penghargaan di...</td>\n      <td>kembang etle polda dapat harga di rakernis fun...</td>\n      <td>develop etle , 7 regional police won awards at...</td>\n      <td>develop etl region polic award gakum function ...</td>\n      <td>1</td>\n      <td>kembangkan etle , 7 polda dapat penghargaan di...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sosialisasi etle dan app smart city</td>\n      <td>sosialisasi etle dan app smart city</td>\n      <td>etle socialization and smart city app</td>\n      <td>etl social smart citi app</td>\n      <td>1</td>\n      <td>sosialisasi etle dan app smart city</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>berita populer kumparanoto , selasa 1312 detai...</td>\n      <td>berita populer kumparanoto selasa detail vespa...</td>\n      <td>Kupang Popular News, Tuesday 1312 details Vesp...</td>\n      <td>kupang popular news tuesday detail vespa batik...</td>\n      <td>1</td>\n      <td>berita populer kumparanoto , selasa 1312 detai...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mimin kasih info ya gaes , kita mau uji coba e...</td>\n      <td>mimin kasih info ya gaes kita mau uji coba etl...</td>\n      <td>Mimin, give me some info, guys, we want to try...</td>\n      <td>mimin give info guy want tri etl tangerang cit...</td>\n      <td>-1</td>\n      <td>mimin kasih informasi iya teman-teman , kita m...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>personil lalu lintas polres badung melaksanaka...</td>\n      <td>personil lalu lintas polres badung laksana teg...</td>\n      <td>Badung Police traffic personnel carry out a hu...</td>\n      <td>badung polic traffic personnel carri human war...</td>\n      <td>-1</td>\n      <td>personil lalu lintas polres badung melaksanaka...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_try.iloc[]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
